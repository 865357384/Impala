# binding predicates of b.month equiv class gets propagated into union
select * from
  (select year, month from functional.alltypes
   union all
   select year, month from functional.alltypes) a
  inner join
  functional.alltypessmall b
  on (a.month = b.month)
where b.month = 1
---- PLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  4:HASH JOIN
  |  join op: INNER JOIN
  |  hash predicates:
  |    b.month = month
  |
  |----0:MERGE
  |    |
  |    |----2:SCAN HDFS
  |    |       table=functional.alltypes #partitions=2/24 size=40.32KB compact
  |    |
  |    1:SCAN HDFS
  |       table=functional.alltypes #partitions=2/24 size=40.32KB compact
  |
  3:SCAN HDFS
     table=functional.alltypessmall #partitions=1/4 size=1.57KB
---- DISTRIBUTEDPLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  10:EXCHANGE

PLAN FRAGMENT 1
  PARTITION: HASH_PARTITIONED: b.month

  STREAM DATA SINK
    EXCHANGE ID: 10
    UNPARTITIONED

  4:HASH JOIN
  |  join op: INNER JOIN (PARTITIONED)
  |  hash predicates:
  |    b.month = month
  |
  |----9:EXCHANGE
  |
  8:EXCHANGE

PLAN FRAGMENT 2
  PARTITION: UNPARTITIONED

  STREAM DATA SINK
    EXCHANGE ID: 9
    HASH_PARTITIONED: month

  5:EXCHANGE

PLAN FRAGMENT 3
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 5
    UNPARTITIONED

  7:MERGE
  |
  2:SCAN HDFS
     table=functional.alltypes #partitions=2/24 size=40.32KB compact

PLAN FRAGMENT 4
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 5
    UNPARTITIONED

  6:MERGE
  |
  1:SCAN HDFS
     table=functional.alltypes #partitions=2/24 size=40.32KB compact

PLAN FRAGMENT 5
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 8
    HASH_PARTITIONED: b.month

  3:SCAN HDFS
     table=functional.alltypessmall #partitions=1/4 size=1.57KB
====
// Only UNION ALL, no nested unions
select * from functional.alltypestiny where year=2009 and month=1
union all
select * from functional.alltypestiny where year=2009 and month=1
union all
select * from functional.alltypestiny where year=2009 and month=2
---- PLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  0:MERGE
  |
  |----3:SCAN HDFS
  |       table=functional.alltypestiny #partitions=1/4 size=115B
  |
  |----2:SCAN HDFS
  |       table=functional.alltypestiny #partitions=1/4 size=115B
  |
  1:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B
---- DISTRIBUTEDPLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  4:EXCHANGE

PLAN FRAGMENT 1
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 4
    UNPARTITIONED

  7:MERGE
  |
  3:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B

PLAN FRAGMENT 2
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 4
    UNPARTITIONED

  6:MERGE
  |
  2:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B

PLAN FRAGMENT 3
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 4
    UNPARTITIONED

  5:MERGE
  |
  1:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B
---- SCANRANGELOCATIONS
NODE 1:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 2:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 3:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=2/090201.txt 0:115
====
// Only UNION ALL with limit inside operands. One of the operands also has an order by.
select * from functional.alltypestiny where year=2009 and month=1 limit 1
union all
select * from functional.alltypestiny where year=2009 and month=1 order by int_col limit 1
union all
select * from functional.alltypestiny where year=2009 and month=2 limit 1
---- PLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  0:MERGE
  |
  |----4:SCAN HDFS
  |       table=functional.alltypestiny #partitions=1/4 size=115B
  |       limit: 1
  |
  |----3:TOP-N
  |    |  order by: int_col ASC
  |    |  limit: 1
  |    |
  |    2:SCAN HDFS
  |       table=functional.alltypestiny #partitions=1/4 size=115B
  |
  1:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B
     limit: 1
---- DISTRIBUTEDPLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  9:EXCHANGE

PLAN FRAGMENT 1
  PARTITION: UNPARTITIONED

  STREAM DATA SINK
    EXCHANGE ID: 9
    UNPARTITIONED

  12:MERGE
  |
  8:EXCHANGE
     limit: 1

PLAN FRAGMENT 2
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 8
    UNPARTITIONED

  4:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B
     limit: 1

PLAN FRAGMENT 3
  PARTITION: UNPARTITIONED

  STREAM DATA SINK
    EXCHANGE ID: 9
    UNPARTITIONED

  11:MERGE
  |
  7:TOP-N
  |  order by: int_col ASC
  |  limit: 1
  |
  6:EXCHANGE

PLAN FRAGMENT 4
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 6
    UNPARTITIONED

  3:TOP-N
  |  order by: int_col ASC
  |  limit: 1
  |
  2:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B

PLAN FRAGMENT 5
  PARTITION: UNPARTITIONED

  STREAM DATA SINK
    EXCHANGE ID: 9
    UNPARTITIONED

  10:MERGE
  |
  5:EXCHANGE
     limit: 1

PLAN FRAGMENT 6
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 5
    UNPARTITIONED

  1:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B
     limit: 1
---- SCANRANGELOCATIONS
NODE 1:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 2:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 4:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=2/090201.txt 0:115
====
// Only UNION DISTINCT, no nested unions
select * from functional.alltypestiny where year=2009 and month=1
union distinct
select * from functional.alltypestiny where year=2009 and month=1
union distinct
select * from functional.alltypestiny where year=2009 and month=2
---- PLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  4:AGGREGATE (finalize)
  |  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
  |
  0:MERGE
  |
  |----3:SCAN HDFS
  |       table=functional.alltypestiny #partitions=1/4 size=115B
  |
  |----2:SCAN HDFS
  |       table=functional.alltypestiny #partitions=1/4 size=115B
  |
  1:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B
---- DISTRIBUTEDPLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  4:AGGREGATE (finalize)
  |  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
  |
  5:EXCHANGE

PLAN FRAGMENT 1
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 5
    UNPARTITIONED

  8:MERGE
  |
  3:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B

PLAN FRAGMENT 2
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 5
    UNPARTITIONED

  7:MERGE
  |
  2:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B

PLAN FRAGMENT 3
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 5
    UNPARTITIONED

  6:MERGE
  |
  1:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B
---- SCANRANGELOCATIONS
NODE 1:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 2:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 3:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=2/090201.txt 0:115
====
// Only UNION ALL, mixed selects with and without from clauses, no nested unions
select * from functional.alltypestiny where year=2009 and month=1
union all
select 0,true,0,0,0,0,0,0,'01/01/09','0',cast('2009-01-01 00:00:00' as timestamp),2009,1
union all
select * from functional.alltypestiny where year=2009 and month=1
union all
select 1,false,1,1,1,10,1.1,10.1,'01/01/09','1',cast('2009-01-01 00:01:00' as timestamp),2009,1
---- PLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  0:MERGE
  |  merging 2 SELECT CONSTANT
  |
  |----2:SCAN HDFS
  |       table=functional.alltypestiny #partitions=1/4 size=115B
  |
  1:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B
---- DISTRIBUTEDPLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  3:EXCHANGE

PLAN FRAGMENT 1
  PARTITION: UNPARTITIONED

  STREAM DATA SINK
    EXCHANGE ID: 3
    UNPARTITIONED

  6:MERGE
     merging 2 SELECT CONSTANT

PLAN FRAGMENT 2
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 3
    UNPARTITIONED

  5:MERGE
  |
  2:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B

PLAN FRAGMENT 3
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 3
    UNPARTITIONED

  4:MERGE
  |
  1:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B
---- SCANRANGELOCATIONS
NODE 1:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 2:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
====
// Only UNION DISTINCT, mixed selects with and without from clauses, no nested unions
select * from functional.alltypestiny where year=2009 and month=1
union distinct
select 0,true,0,0,0,0,0,0,'01/01/09','0',cast('2009-01-01 00:00:00' as timestamp),2009,1
union distinct
select * from functional.alltypestiny where year=2009 and month=1
union distinct
select 1,false,1,1,1,10,1.1,10.1,'01/01/09','1',cast('2009-01-01 00:01:00' as timestamp),2009,1
---- PLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  3:AGGREGATE (finalize)
  |  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
  |
  0:MERGE
  |  merging 2 SELECT CONSTANT
  |
  |----2:SCAN HDFS
  |       table=functional.alltypestiny #partitions=1/4 size=115B
  |
  1:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B
---- DISTRIBUTEDPLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  3:AGGREGATE (finalize)
  |  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
  |
  4:EXCHANGE

PLAN FRAGMENT 1
  PARTITION: UNPARTITIONED

  STREAM DATA SINK
    EXCHANGE ID: 4
    UNPARTITIONED

  7:MERGE
     merging 2 SELECT CONSTANT

PLAN FRAGMENT 2
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 4
    UNPARTITIONED

  6:MERGE
  |
  2:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B

PLAN FRAGMENT 3
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 4
    UNPARTITIONED

  5:MERGE
  |
  1:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B
---- SCANRANGELOCATIONS
NODE 1:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 2:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
====
// Mixed UNION ALL/DISTINCT but effectively only UNION DISTINCT, no nested unions,
// with order by and limit
select * from functional.alltypestiny where year=2009 and month=1
union all
select * from functional.alltypestiny where year=2009 and month=1
union all
select * from functional.alltypestiny where year=2009 and month=2
union distinct
(select * from functional.alltypestiny where year=2009 and month=2)
order by 3 limit 3
---- PLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  6:TOP-N
  |  order by: tinyint_col ASC
  |  limit: 3
  |
  5:AGGREGATE (finalize)
  |  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
  |
  0:MERGE
  |
  |----4:SCAN HDFS
  |       table=functional.alltypestiny #partitions=1/4 size=115B
  |
  |----3:SCAN HDFS
  |       table=functional.alltypestiny #partitions=1/4 size=115B
  |
  |----2:SCAN HDFS
  |       table=functional.alltypestiny #partitions=1/4 size=115B
  |
  1:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B
---- DISTRIBUTEDPLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  6:TOP-N
  |  order by: tinyint_col ASC
  |  limit: 3
  |
  5:AGGREGATE (finalize)
  |  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
  |
  7:EXCHANGE

PLAN FRAGMENT 1
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 7
    UNPARTITIONED

  11:MERGE
  |
  4:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B

PLAN FRAGMENT 2
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 7
    UNPARTITIONED

  10:MERGE
  |
  3:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B

PLAN FRAGMENT 3
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 7
    UNPARTITIONED

  9:MERGE
  |
  2:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B

PLAN FRAGMENT 4
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 7
    UNPARTITIONED

  8:MERGE
  |
  1:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B
---- SCANRANGELOCATIONS
NODE 1:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 2:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 3:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=2/090201.txt 0:115
NODE 4:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=2/090201.txt 0:115
====
// Mixed UNION ALL/DISTINCT, no nested unions, with order by and limit
select * from functional.alltypestiny where year=2009 and month=1
union distinct
select * from functional.alltypestiny where year=2009 and month=1
union all
select * from functional.alltypestiny where year=2009 and month=2
union all
(select * from functional.alltypestiny where year=2009 and month=2)
order by 3,4 limit 3
---- PLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  7:TOP-N
  |  order by: tinyint_col ASC, smallint_col ASC
  |  limit: 3
  |
  4:MERGE
  |
  |----3:AGGREGATE (finalize)
  |    |  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
  |    |
  |    0:MERGE
  |    |
  |    |----2:SCAN HDFS
  |    |       table=functional.alltypestiny #partitions=1/4 size=115B
  |    |
  |    1:SCAN HDFS
  |       table=functional.alltypestiny #partitions=1/4 size=115B
  |
  |----6:SCAN HDFS
  |       table=functional.alltypestiny #partitions=1/4 size=115B
  |
  5:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B
---- DISTRIBUTEDPLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  7:TOP-N
  |  order by: tinyint_col ASC, smallint_col ASC
  |  limit: 3
  |
  11:EXCHANGE

PLAN FRAGMENT 1
  PARTITION: UNPARTITIONED

  STREAM DATA SINK
    EXCHANGE ID: 11
    UNPARTITIONED

  14:MERGE
  |
  3:AGGREGATE (finalize)
  |  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
  |
  8:EXCHANGE

PLAN FRAGMENT 2
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 8
    UNPARTITIONED

  10:MERGE
  |
  2:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B

PLAN FRAGMENT 3
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 8
    UNPARTITIONED

  9:MERGE
  |
  1:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B

PLAN FRAGMENT 4
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 11
    UNPARTITIONED

  13:MERGE
  |
  6:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B

PLAN FRAGMENT 5
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 11
    UNPARTITIONED

  12:MERGE
  |
  5:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B
---- SCANRANGELOCATIONS
NODE 1:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 2:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 5:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=2/090201.txt 0:115
NODE 6:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=2/090201.txt 0:115
====
// Mixed UNION ALL/DISTINCT, no nested unions, with order by and limit
select * from functional.alltypestiny where year=2009 and month=1
union all
select * from functional.alltypestiny where year=2009 and month=1
union distinct
select * from functional.alltypestiny where year=2009 and month=2
union all
(select * from functional.alltypestiny where year=2009 and month=2)
order by 3,4 limit 4
---- PLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  7:TOP-N
  |  order by: tinyint_col ASC, smallint_col ASC
  |  limit: 4
  |
  5:MERGE
  |
  |----4:AGGREGATE (finalize)
  |    |  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
  |    |
  |    0:MERGE
  |    |
  |    |----3:SCAN HDFS
  |    |       table=functional.alltypestiny #partitions=1/4 size=115B
  |    |
  |    |----2:SCAN HDFS
  |    |       table=functional.alltypestiny #partitions=1/4 size=115B
  |    |
  |    1:SCAN HDFS
  |       table=functional.alltypestiny #partitions=1/4 size=115B
  |
  6:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B
---- DISTRIBUTEDPLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  7:TOP-N
  |  order by: tinyint_col ASC, smallint_col ASC
  |  limit: 4
  |
  12:EXCHANGE

PLAN FRAGMENT 1
  PARTITION: UNPARTITIONED

  STREAM DATA SINK
    EXCHANGE ID: 12
    UNPARTITIONED

  14:MERGE
  |
  4:AGGREGATE (finalize)
  |  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
  |
  8:EXCHANGE

PLAN FRAGMENT 2
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 8
    UNPARTITIONED

  11:MERGE
  |
  3:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B

PLAN FRAGMENT 3
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 8
    UNPARTITIONED

  10:MERGE
  |
  2:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B

PLAN FRAGMENT 4
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 8
    UNPARTITIONED

  9:MERGE
  |
  1:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B

PLAN FRAGMENT 5
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 12
    UNPARTITIONED

  13:MERGE
  |
  6:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B
---- SCANRANGELOCATIONS
NODE 1:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 2:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 3:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=2/090201.txt 0:115
NODE 6:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=2/090201.txt 0:115
====
// Union unnesting: Only UNION ALL, first operand is nested
(select * from functional.alltypestiny where year=2009 and month=1
 union all
 select * from functional.alltypestiny where year=2009 and month=2)
union all
select * from functional.alltypestiny where year=2009 and month=1
---- PLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  0:MERGE
  |
  |----3:SCAN HDFS
  |       table=functional.alltypestiny #partitions=1/4 size=115B
  |
  |----2:SCAN HDFS
  |       table=functional.alltypestiny #partitions=1/4 size=115B
  |
  1:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B
---- DISTRIBUTEDPLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  4:EXCHANGE

PLAN FRAGMENT 1
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 4
    UNPARTITIONED

  7:MERGE
  |
  3:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B

PLAN FRAGMENT 2
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 4
    UNPARTITIONED

  6:MERGE
  |
  2:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B

PLAN FRAGMENT 3
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 4
    UNPARTITIONED

  5:MERGE
  |
  1:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B
---- SCANRANGELOCATIONS
NODE 1:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 2:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=2/090201.txt 0:115
NODE 3:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
====
// Union unnesting: Only UNION ALL, second operand is nested
select * from functional.alltypestiny where year=2009 and month=1
union all
  (select * from functional.alltypestiny where year=2009 and month=1
   union all
   select * from functional.alltypestiny where year=2009 and month=2)
---- PLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  0:MERGE
  |
  |----3:SCAN HDFS
  |       table=functional.alltypestiny #partitions=1/4 size=115B
  |
  |----2:SCAN HDFS
  |       table=functional.alltypestiny #partitions=1/4 size=115B
  |
  1:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B
---- DISTRIBUTEDPLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  4:EXCHANGE

PLAN FRAGMENT 1
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 4
    UNPARTITIONED

  7:MERGE
  |
  3:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B

PLAN FRAGMENT 2
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 4
    UNPARTITIONED

  6:MERGE
  |
  2:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B

PLAN FRAGMENT 3
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 4
    UNPARTITIONED

  5:MERGE
  |
  1:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B
---- SCANRANGELOCATIONS
NODE 1:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 2:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 3:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=2/090201.txt 0:115
====
// Union unnesting: Only UNION DISTINCT, first operand is nested
(select * from functional.alltypestiny where year=2009 and month=1
 union distinct
 select * from functional.alltypestiny where year=2009 and month=2)
union distinct
select * from functional.alltypestiny where year=2009 and month=1
---- PLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  4:AGGREGATE (finalize)
  |  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
  |
  0:MERGE
  |
  |----3:SCAN HDFS
  |       table=functional.alltypestiny #partitions=1/4 size=115B
  |
  |----2:SCAN HDFS
  |       table=functional.alltypestiny #partitions=1/4 size=115B
  |
  1:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B
---- DISTRIBUTEDPLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  4:AGGREGATE (finalize)
  |  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
  |
  5:EXCHANGE

PLAN FRAGMENT 1
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 5
    UNPARTITIONED

  8:MERGE
  |
  3:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B

PLAN FRAGMENT 2
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 5
    UNPARTITIONED

  7:MERGE
  |
  2:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B

PLAN FRAGMENT 3
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 5
    UNPARTITIONED

  6:MERGE
  |
  1:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B
---- SCANRANGELOCATIONS
NODE 1:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 2:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=2/090201.txt 0:115
NODE 3:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
====
// Union unnesting: Only UNION DISTINCT, second operand is nested
select * from functional.alltypestiny where year=2009 and month=1
union distinct
  (select * from functional.alltypestiny where year=2009 and month=1
   union distinct
   select * from functional.alltypestiny where year=2009 and month=2)
---- PLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  4:AGGREGATE (finalize)
  |  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
  |
  0:MERGE
  |
  |----3:SCAN HDFS
  |       table=functional.alltypestiny #partitions=1/4 size=115B
  |
  |----2:SCAN HDFS
  |       table=functional.alltypestiny #partitions=1/4 size=115B
  |
  1:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B
---- DISTRIBUTEDPLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  4:AGGREGATE (finalize)
  |  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
  |
  5:EXCHANGE

PLAN FRAGMENT 1
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 5
    UNPARTITIONED

  8:MERGE
  |
  3:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B

PLAN FRAGMENT 2
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 5
    UNPARTITIONED

  7:MERGE
  |
  2:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B

PLAN FRAGMENT 3
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 5
    UNPARTITIONED

  6:MERGE
  |
  1:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B
---- SCANRANGELOCATIONS
NODE 1:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 2:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 3:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=2/090201.txt 0:115
====
// Union unnesting: UNION ALL doesn't absorb nested union with DISTINCT,
// first operand is nested
(select * from functional.alltypestiny where year=2009 and month=1
 union distinct
 select * from functional.alltypestiny where year=2009 and month=2)
union all
select * from functional.alltypestiny where year=2009 and month=1
---- PLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  0:MERGE
  |
  |----5:SCAN HDFS
  |       table=functional.alltypestiny #partitions=1/4 size=115B
  |
  4:AGGREGATE (finalize)
  |  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
  |
  1:MERGE
  |
  |----3:SCAN HDFS
  |       table=functional.alltypestiny #partitions=1/4 size=115B
  |
  2:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B
---- DISTRIBUTEDPLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  9:EXCHANGE

PLAN FRAGMENT 1
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 9
    UNPARTITIONED

  11:MERGE
  |
  5:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B

PLAN FRAGMENT 2
  PARTITION: UNPARTITIONED

  STREAM DATA SINK
    EXCHANGE ID: 9
    UNPARTITIONED

  10:MERGE
  |
  4:AGGREGATE (finalize)
  |  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
  |
  6:EXCHANGE

PLAN FRAGMENT 3
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 6
    UNPARTITIONED

  8:MERGE
  |
  3:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B

PLAN FRAGMENT 4
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 6
    UNPARTITIONED

  7:MERGE
  |
  2:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B
---- SCANRANGELOCATIONS
NODE 2:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 3:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=2/090201.txt 0:115
NODE 5:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
====
// Union unnesting: UNION ALL doesn't absorb nested union with DISTINCT,
// second operand is nested
select * from functional.alltypestiny where year=2009 and month=1
union all
  (select * from functional.alltypestiny where year=2009 and month=1
   union distinct
   select * from functional.alltypestiny where year=2009 and month=2)
---- PLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  0:MERGE
  |
  |----5:AGGREGATE (finalize)
  |    |  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
  |    |
  |    2:MERGE
  |    |
  |    |----4:SCAN HDFS
  |    |       table=functional.alltypestiny #partitions=1/4 size=115B
  |    |
  |    3:SCAN HDFS
  |       table=functional.alltypestiny #partitions=1/4 size=115B
  |
  1:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B
---- DISTRIBUTEDPLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  9:EXCHANGE

PLAN FRAGMENT 1
  PARTITION: UNPARTITIONED

  STREAM DATA SINK
    EXCHANGE ID: 9
    UNPARTITIONED

  11:MERGE
  |
  5:AGGREGATE (finalize)
  |  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
  |
  6:EXCHANGE

PLAN FRAGMENT 2
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 6
    UNPARTITIONED

  8:MERGE
  |
  4:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B

PLAN FRAGMENT 3
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 6
    UNPARTITIONED

  7:MERGE
  |
  3:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B

PLAN FRAGMENT 4
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 9
    UNPARTITIONED

  10:MERGE
  |
  1:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B
---- SCANRANGELOCATIONS
NODE 1:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 3:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 4:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=2/090201.txt 0:115
====
// Union unnesting: UNION ALL absorbs the children but not directly the operands
// of a nested union with mixed ALL/DISTINCT, first operand is nested
(select * from functional.alltypestiny where year=2009 and month=1
 union distinct
 select * from functional.alltypestiny where year=2009 and month=2
 union all
 select * from functional.alltypestiny where year=2009 and month=2)
union all
select * from functional.alltypestiny where year=2009 and month=1
---- PLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  0:MERGE
  |
  |----6:SCAN HDFS
  |       table=functional.alltypestiny #partitions=1/4 size=115B
  |
  |----5:AGGREGATE (finalize)
  |    |  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
  |    |
  |    2:MERGE
  |    |
  |    |----4:SCAN HDFS
  |    |       table=functional.alltypestiny #partitions=1/4 size=115B
  |    |
  |    3:SCAN HDFS
  |       table=functional.alltypestiny #partitions=1/4 size=115B
  |
  1:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B
---- DISTRIBUTEDPLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  10:EXCHANGE

PLAN FRAGMENT 1
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 10
    UNPARTITIONED

  13:MERGE
  |
  6:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B

PLAN FRAGMENT 2
  PARTITION: UNPARTITIONED

  STREAM DATA SINK
    EXCHANGE ID: 10
    UNPARTITIONED

  12:MERGE
  |
  5:AGGREGATE (finalize)
  |  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
  |
  7:EXCHANGE

PLAN FRAGMENT 3
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 7
    UNPARTITIONED

  9:MERGE
  |
  4:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B

PLAN FRAGMENT 4
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 7
    UNPARTITIONED

  8:MERGE
  |
  3:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B

PLAN FRAGMENT 5
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 10
    UNPARTITIONED

  11:MERGE
  |
  1:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B
---- SCANRANGELOCATIONS
NODE 1:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=2/090201.txt 0:115
NODE 3:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 4:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=2/090201.txt 0:115
NODE 6:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
====
// Union unnesting: UNION ALL absorbs the children but not directly the operands
// of a nested union with mixed ALL/DISTINCT, second operand is nested
select * from functional.alltypestiny where year=2009 and month=1
union all
  (select * from functional.alltypestiny where year=2009 and month=1
   union distinct
   select * from functional.alltypestiny where year=2009 and month=2
   union all
   select * from functional.alltypestiny where year=2009 and month=2)
---- PLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  0:MERGE
  |
  |----6:AGGREGATE (finalize)
  |    |  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
  |    |
  |    3:MERGE
  |    |
  |    |----5:SCAN HDFS
  |    |       table=functional.alltypestiny #partitions=1/4 size=115B
  |    |
  |    4:SCAN HDFS
  |       table=functional.alltypestiny #partitions=1/4 size=115B
  |
  |----2:SCAN HDFS
  |       table=functional.alltypestiny #partitions=1/4 size=115B
  |
  1:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B
---- DISTRIBUTEDPLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  10:EXCHANGE

PLAN FRAGMENT 1
  PARTITION: UNPARTITIONED

  STREAM DATA SINK
    EXCHANGE ID: 10
    UNPARTITIONED

  13:MERGE
  |
  6:AGGREGATE (finalize)
  |  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
  |
  7:EXCHANGE

PLAN FRAGMENT 2
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 7
    UNPARTITIONED

  9:MERGE
  |
  5:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B

PLAN FRAGMENT 3
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 7
    UNPARTITIONED

  8:MERGE
  |
  4:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B

PLAN FRAGMENT 4
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 10
    UNPARTITIONED

  12:MERGE
  |
  2:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B

PLAN FRAGMENT 5
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 10
    UNPARTITIONED

  11:MERGE
  |
  1:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B
---- SCANRANGELOCATIONS
NODE 1:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 2:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=2/090201.txt 0:115
NODE 4:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 5:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=2/090201.txt 0:115
====
// Union unnesting: UNION ALL doesn't absorb the children of a nested union
// with mixed ALL/DISTINCT and limit, second operand is nested
select * from functional.alltypestiny where year=2009 and month=1
union all
  (select * from functional.alltypestiny where year=2009 and month=1
   union distinct
   select * from functional.alltypestiny where year=2009 and month=2
   union all
   (select * from functional.alltypestiny where year=2009 and month=2)
   limit 10)
---- PLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  0:MERGE
  |
  |----6:MERGE
  |    |  limit: 10
  |    |
  |    |----5:AGGREGATE (finalize)
  |    |    |  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
  |    |    |
  |    |    2:MERGE
  |    |    |
  |    |    |----4:SCAN HDFS
  |    |    |       table=functional.alltypestiny #partitions=1/4 size=115B
  |    |    |
  |    |    3:SCAN HDFS
  |    |       table=functional.alltypestiny #partitions=1/4 size=115B
  |    |
  |    7:SCAN HDFS
  |       table=functional.alltypestiny #partitions=1/4 size=115B
  |
  1:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B
---- DISTRIBUTEDPLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  14:EXCHANGE

PLAN FRAGMENT 1
  PARTITION: UNPARTITIONED

  STREAM DATA SINK
    EXCHANGE ID: 14
    UNPARTITIONED

  16:MERGE
  |
  11:EXCHANGE
     limit: 10

PLAN FRAGMENT 2
  PARTITION: UNPARTITIONED

  STREAM DATA SINK
    EXCHANGE ID: 11
    UNPARTITIONED

  13:MERGE
  |  limit: 10
  |
  5:AGGREGATE (finalize)
  |  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
  |
  8:EXCHANGE

PLAN FRAGMENT 3
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 8
    UNPARTITIONED

  10:MERGE
  |
  4:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B

PLAN FRAGMENT 4
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 8
    UNPARTITIONED

  9:MERGE
  |
  3:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B

PLAN FRAGMENT 5
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 11
    UNPARTITIONED

  12:MERGE
  |  limit: 10
  |
  7:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B

PLAN FRAGMENT 6
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 14
    UNPARTITIONED

  15:MERGE
  |
  1:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B
---- SCANRANGELOCATIONS
NODE 1:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 3:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 4:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=2/090201.txt 0:115
NODE 7:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=2/090201.txt 0:115
====
// Union unnesting: UNION ALL doesn't absorb nested union with order by and limit,
// first operand is nested
(select * from functional.alltypestiny where year=2009 and month=1
 union all
 (select * from functional.alltypestiny where year=2009 and month=2)
 order by 3 limit 3)
union all
select * from functional.alltypestiny where year=2009 and month=1
---- PLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  0:MERGE
  |
  |----5:SCAN HDFS
  |       table=functional.alltypestiny #partitions=1/4 size=115B
  |
  4:TOP-N
  |  order by: tinyint_col ASC
  |  limit: 3
  |
  1:MERGE
  |
  |----3:SCAN HDFS
  |       table=functional.alltypestiny #partitions=1/4 size=115B
  |
  2:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B
---- DISTRIBUTEDPLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  9:EXCHANGE

PLAN FRAGMENT 1
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 9
    UNPARTITIONED

  11:MERGE
  |
  5:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B

PLAN FRAGMENT 2
  PARTITION: UNPARTITIONED

  STREAM DATA SINK
    EXCHANGE ID: 9
    UNPARTITIONED

  10:MERGE
  |
  4:TOP-N
  |  order by: tinyint_col ASC
  |  limit: 3
  |
  6:EXCHANGE

PLAN FRAGMENT 3
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 6
    UNPARTITIONED

  8:MERGE
  |
  3:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B

PLAN FRAGMENT 4
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 6
    UNPARTITIONED

  7:MERGE
  |
  2:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B
---- SCANRANGELOCATIONS
NODE 2:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 3:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=2/090201.txt 0:115
NODE 5:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
====
// Union unnesting: UNION ALL doesn't absorb nested union with order by and limit,
// second operand is nested
select * from functional.alltypestiny where year=2009 and month=1
union all
  (select * from functional.alltypestiny where year=2009 and month=1
   union all
   (select * from functional.alltypestiny where year=2009 and month=2)
   order by 3 limit 3)
---- PLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  0:MERGE
  |
  |----5:TOP-N
  |    |  order by: tinyint_col ASC
  |    |  limit: 3
  |    |
  |    2:MERGE
  |    |
  |    |----4:SCAN HDFS
  |    |       table=functional.alltypestiny #partitions=1/4 size=115B
  |    |
  |    3:SCAN HDFS
  |       table=functional.alltypestiny #partitions=1/4 size=115B
  |
  1:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B
---- DISTRIBUTEDPLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  9:EXCHANGE

PLAN FRAGMENT 1
  PARTITION: UNPARTITIONED

  STREAM DATA SINK
    EXCHANGE ID: 9
    UNPARTITIONED

  11:MERGE
  |
  5:TOP-N
  |  order by: tinyint_col ASC
  |  limit: 3
  |
  6:EXCHANGE

PLAN FRAGMENT 2
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 6
    UNPARTITIONED

  8:MERGE
  |
  4:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B

PLAN FRAGMENT 3
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 6
    UNPARTITIONED

  7:MERGE
  |
  3:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B

PLAN FRAGMENT 4
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 9
    UNPARTITIONED

  10:MERGE
  |
  1:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B
---- SCANRANGELOCATIONS
NODE 1:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 3:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 4:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=2/090201.txt 0:115
====
// Union unnesting: UNION DISTINCT absorbs nested union with ALL
// first operand is nested
(select * from functional.alltypestiny where year=2009 and month=1
 union all
 select * from functional.alltypestiny where year=2009 and month=2)
union distinct
select * from functional.alltypestiny where year=2009 and month=1
---- PLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  4:AGGREGATE (finalize)
  |  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
  |
  0:MERGE
  |
  |----3:SCAN HDFS
  |       table=functional.alltypestiny #partitions=1/4 size=115B
  |
  |----2:SCAN HDFS
  |       table=functional.alltypestiny #partitions=1/4 size=115B
  |
  1:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B
---- DISTRIBUTEDPLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  4:AGGREGATE (finalize)
  |  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
  |
  5:EXCHANGE

PLAN FRAGMENT 1
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 5
    UNPARTITIONED

  8:MERGE
  |
  3:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B

PLAN FRAGMENT 2
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 5
    UNPARTITIONED

  7:MERGE
  |
  2:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B

PLAN FRAGMENT 3
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 5
    UNPARTITIONED

  6:MERGE
  |
  1:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B
---- SCANRANGELOCATIONS
NODE 1:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 2:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=2/090201.txt 0:115
NODE 3:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
====
// Union unnesting: UNION DISTINCT absorbs nested union with ALL,
// second operand is nested
select * from functional.alltypestiny where year=2009 and month=1
union distinct
  (select * from functional.alltypestiny where year=2009 and month=1
   union all
   select * from functional.alltypestiny where year=2009 and month=2)
---- PLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  4:AGGREGATE (finalize)
  |  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
  |
  0:MERGE
  |
  |----3:SCAN HDFS
  |       table=functional.alltypestiny #partitions=1/4 size=115B
  |
  |----2:SCAN HDFS
  |       table=functional.alltypestiny #partitions=1/4 size=115B
  |
  1:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B
---- DISTRIBUTEDPLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  4:AGGREGATE (finalize)
  |  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
  |
  5:EXCHANGE

PLAN FRAGMENT 1
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 5
    UNPARTITIONED

  8:MERGE
  |
  3:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B

PLAN FRAGMENT 2
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 5
    UNPARTITIONED

  7:MERGE
  |
  2:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B

PLAN FRAGMENT 3
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 5
    UNPARTITIONED

  6:MERGE
  |
  1:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B
---- SCANRANGELOCATIONS
NODE 1:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 2:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 3:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=2/090201.txt 0:115
====
// Union unnesting: UNION DISTINCT absorbs nested union with mixed ALL/DISTINCT,
// first operand is nested
(select * from functional.alltypestiny where year=2009 and month=1
 union distinct
 select * from functional.alltypestiny where year=2009 and month=2
 union all
 select * from functional.alltypestiny where year=2009 and month=2)
union distinct
select * from functional.alltypestiny where year=2009 and month=1
---- PLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  5:AGGREGATE (finalize)
  |  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
  |
  0:MERGE
  |
  |----4:SCAN HDFS
  |       table=functional.alltypestiny #partitions=1/4 size=115B
  |
  |----3:SCAN HDFS
  |       table=functional.alltypestiny #partitions=1/4 size=115B
  |
  |----2:SCAN HDFS
  |       table=functional.alltypestiny #partitions=1/4 size=115B
  |
  1:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B
---- DISTRIBUTEDPLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  5:AGGREGATE (finalize)
  |  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
  |
  6:EXCHANGE

PLAN FRAGMENT 1
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 6
    UNPARTITIONED

  10:MERGE
  |
  4:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B

PLAN FRAGMENT 2
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 6
    UNPARTITIONED

  9:MERGE
  |
  3:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B

PLAN FRAGMENT 3
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 6
    UNPARTITIONED

  8:MERGE
  |
  2:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B

PLAN FRAGMENT 4
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 6
    UNPARTITIONED

  7:MERGE
  |
  1:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B
---- SCANRANGELOCATIONS
NODE 1:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 2:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=2/090201.txt 0:115
NODE 3:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=2/090201.txt 0:115
NODE 4:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
====
// Union unnesting: UNION DISTINCT absorbs nested union with mixed ALL/DISTINCT,
// second operand is nested
select * from functional.alltypestiny where year=2009 and month=1
union distinct
  (select * from functional.alltypestiny where year=2009 and month=1
   union distinct
   select * from functional.alltypestiny where year=2009 and month=2
   union all
   select * from functional.alltypestiny where year=2009 and month=2)
---- PLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  5:AGGREGATE (finalize)
  |  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
  |
  0:MERGE
  |
  |----4:SCAN HDFS
  |       table=functional.alltypestiny #partitions=1/4 size=115B
  |
  |----3:SCAN HDFS
  |       table=functional.alltypestiny #partitions=1/4 size=115B
  |
  |----2:SCAN HDFS
  |       table=functional.alltypestiny #partitions=1/4 size=115B
  |
  1:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B
---- DISTRIBUTEDPLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  5:AGGREGATE (finalize)
  |  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
  |
  6:EXCHANGE

PLAN FRAGMENT 1
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 6
    UNPARTITIONED

  10:MERGE
  |
  4:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B

PLAN FRAGMENT 2
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 6
    UNPARTITIONED

  9:MERGE
  |
  3:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B

PLAN FRAGMENT 3
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 6
    UNPARTITIONED

  8:MERGE
  |
  2:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B

PLAN FRAGMENT 4
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 6
    UNPARTITIONED

  7:MERGE
  |
  1:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B
---- SCANRANGELOCATIONS
NODE 1:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 2:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 3:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=2/090201.txt 0:115
NODE 4:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=2/090201.txt 0:115
====
// Union unnesting: UNION DISTINCT doesn't absorb nested union with order by and limit,
// first operand is nested
(select * from functional.alltypestiny where year=2009 and month=1
 union all
 (select * from functional.alltypestiny where year=2009 and month=2)
 order by 3 limit 3)
union distinct
select * from functional.alltypestiny where year=2009 and month=1
---- PLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  6:AGGREGATE (finalize)
  |  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
  |
  0:MERGE
  |
  |----5:SCAN HDFS
  |       table=functional.alltypestiny #partitions=1/4 size=115B
  |
  4:TOP-N
  |  order by: tinyint_col ASC
  |  limit: 3
  |
  1:MERGE
  |
  |----3:SCAN HDFS
  |       table=functional.alltypestiny #partitions=1/4 size=115B
  |
  2:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B
---- DISTRIBUTEDPLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  6:AGGREGATE (finalize)
  |  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
  |
  10:EXCHANGE

PLAN FRAGMENT 1
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 10
    UNPARTITIONED

  12:MERGE
  |
  5:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B

PLAN FRAGMENT 2
  PARTITION: UNPARTITIONED

  STREAM DATA SINK
    EXCHANGE ID: 10
    UNPARTITIONED

  11:MERGE
  |
  4:TOP-N
  |  order by: tinyint_col ASC
  |  limit: 3
  |
  7:EXCHANGE

PLAN FRAGMENT 3
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 7
    UNPARTITIONED

  9:MERGE
  |
  3:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B

PLAN FRAGMENT 4
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 7
    UNPARTITIONED

  8:MERGE
  |
  2:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B
---- SCANRANGELOCATIONS
NODE 2:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 3:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=2/090201.txt 0:115
NODE 5:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
====
// Union unnesting: UNION DISTINCT doesn't absorb nested union with order by and limit
// second operand is nested
select * from functional.alltypestiny where year=2009 and month=1
union distinct
  (select * from functional.alltypestiny where year=2009 and month=1
   union all
   (select * from functional.alltypestiny where year=2009 and month=2)
   order by 3 limit 3)
---- PLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  6:AGGREGATE (finalize)
  |  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
  |
  0:MERGE
  |
  |----5:TOP-N
  |    |  order by: tinyint_col ASC
  |    |  limit: 3
  |    |
  |    2:MERGE
  |    |
  |    |----4:SCAN HDFS
  |    |       table=functional.alltypestiny #partitions=1/4 size=115B
  |    |
  |    3:SCAN HDFS
  |       table=functional.alltypestiny #partitions=1/4 size=115B
  |
  1:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B
---- DISTRIBUTEDPLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  6:AGGREGATE (finalize)
  |  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
  |
  10:EXCHANGE

PLAN FRAGMENT 1
  PARTITION: UNPARTITIONED

  STREAM DATA SINK
    EXCHANGE ID: 10
    UNPARTITIONED

  12:MERGE
  |
  5:TOP-N
  |  order by: tinyint_col ASC
  |  limit: 3
  |
  7:EXCHANGE

PLAN FRAGMENT 2
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 7
    UNPARTITIONED

  9:MERGE
  |
  4:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B

PLAN FRAGMENT 3
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 7
    UNPARTITIONED

  8:MERGE
  |
  3:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B

PLAN FRAGMENT 4
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 10
    UNPARTITIONED

  11:MERGE
  |
  1:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B
---- SCANRANGELOCATIONS
NODE 1:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 3:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 4:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=2/090201.txt 0:115
====
// Complex union unnesting: Multiple levels of UNION ALL, fully unnestable
select * from functional.alltypestiny where year=2009 and month=1
union all
  (select * from functional.alltypestiny where year=2009 and month=1
   union all
     (select * from functional.alltypestiny where year=2009 and month=2
      union all
        (select * from functional.alltypestiny where year=2009 and month=2
         union all
         select * from functional.alltypestiny where year=2009 and month=3)))
---- PLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  0:MERGE
  |
  |----5:SCAN HDFS
  |       table=functional.alltypestiny #partitions=1/4 size=115B
  |
  |----4:SCAN HDFS
  |       table=functional.alltypestiny #partitions=1/4 size=115B
  |
  |----3:SCAN HDFS
  |       table=functional.alltypestiny #partitions=1/4 size=115B
  |
  |----2:SCAN HDFS
  |       table=functional.alltypestiny #partitions=1/4 size=115B
  |
  1:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B
---- DISTRIBUTEDPLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  6:EXCHANGE

PLAN FRAGMENT 1
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 6
    UNPARTITIONED

  11:MERGE
  |
  5:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B

PLAN FRAGMENT 2
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 6
    UNPARTITIONED

  10:MERGE
  |
  4:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B

PLAN FRAGMENT 3
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 6
    UNPARTITIONED

  9:MERGE
  |
  3:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B

PLAN FRAGMENT 4
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 6
    UNPARTITIONED

  8:MERGE
  |
  2:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B

PLAN FRAGMENT 5
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 6
    UNPARTITIONED

  7:MERGE
  |
  1:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B
---- SCANRANGELOCATIONS
NODE 1:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 2:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 3:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=2/090201.txt 0:115
NODE 4:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=2/090201.txt 0:115
NODE 5:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=3/090301.txt 0:115
====
// Complex union unnesting: Multiple levels of UNION DISTINCT, fully unnestable
select * from functional.alltypestiny where year=2009 and month=1
union distinct
  (select * from functional.alltypestiny where year=2009 and month=1
   union distinct
     (select * from functional.alltypestiny where year=2009 and month=2
      union distinct
        (select * from functional.alltypestiny where year=2009 and month=2
         union distinct
         select * from functional.alltypestiny where year=2009 and month=3)))
---- PLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  6:AGGREGATE (finalize)
  |  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
  |
  0:MERGE
  |
  |----5:SCAN HDFS
  |       table=functional.alltypestiny #partitions=1/4 size=115B
  |
  |----4:SCAN HDFS
  |       table=functional.alltypestiny #partitions=1/4 size=115B
  |
  |----3:SCAN HDFS
  |       table=functional.alltypestiny #partitions=1/4 size=115B
  |
  |----2:SCAN HDFS
  |       table=functional.alltypestiny #partitions=1/4 size=115B
  |
  1:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B
---- DISTRIBUTEDPLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  6:AGGREGATE (finalize)
  |  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
  |
  7:EXCHANGE

PLAN FRAGMENT 1
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 7
    UNPARTITIONED

  12:MERGE
  |
  5:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B

PLAN FRAGMENT 2
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 7
    UNPARTITIONED

  11:MERGE
  |
  4:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B

PLAN FRAGMENT 3
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 7
    UNPARTITIONED

  10:MERGE
  |
  3:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B

PLAN FRAGMENT 4
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 7
    UNPARTITIONED

  9:MERGE
  |
  2:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B

PLAN FRAGMENT 5
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 7
    UNPARTITIONED

  8:MERGE
  |
  1:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B
---- SCANRANGELOCATIONS
NODE 1:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 2:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 3:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=2/090201.txt 0:115
NODE 4:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=2/090201.txt 0:115
NODE 5:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=3/090301.txt 0:115
====
// Complex union unnesting: Partially unnestable up to 2nd level
select * from functional.alltypestiny where year=2009 and month=1
union all
  (select * from functional.alltypestiny where year=2009 and month=1
   union distinct
     (select * from functional.alltypestiny where year=2009 and month=2
      union all
        (select * from functional.alltypestiny where year=2009 and month=2
         union distinct
         (select * from functional.alltypestiny where year=2009 and month=3)
         order by 3 limit 3)))
---- PLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  0:MERGE
  |
  |----10:AGGREGATE (finalize)
  |    |  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
  |    |
  |    2:MERGE
  |    |
  |    |----9:TOP-N
  |    |    |  order by: tinyint_col ASC
  |    |    |  limit: 3
  |    |    |
  |    |    8:AGGREGATE (finalize)
  |    |    |  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
  |    |    |
  |    |    5:MERGE
  |    |    |
  |    |    |----7:SCAN HDFS
  |    |    |       table=functional.alltypestiny #partitions=1/4 size=115B
  |    |    |
  |    |    6:SCAN HDFS
  |    |       table=functional.alltypestiny #partitions=1/4 size=115B
  |    |
  |    |----4:SCAN HDFS
  |    |       table=functional.alltypestiny #partitions=1/4 size=115B
  |    |
  |    3:SCAN HDFS
  |       table=functional.alltypestiny #partitions=1/4 size=115B
  |
  1:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B
---- DISTRIBUTEDPLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  18:EXCHANGE

PLAN FRAGMENT 1
  PARTITION: UNPARTITIONED

  STREAM DATA SINK
    EXCHANGE ID: 18
    UNPARTITIONED

  20:MERGE
  |
  10:AGGREGATE (finalize)
  |  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
  |
  14:EXCHANGE

PLAN FRAGMENT 2
  PARTITION: UNPARTITIONED

  STREAM DATA SINK
    EXCHANGE ID: 14
    UNPARTITIONED

  17:MERGE
  |
  9:TOP-N
  |  order by: tinyint_col ASC
  |  limit: 3
  |
  8:AGGREGATE (finalize)
  |  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
  |
  11:EXCHANGE

PLAN FRAGMENT 3
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 11
    UNPARTITIONED

  13:MERGE
  |
  7:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B

PLAN FRAGMENT 4
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 11
    UNPARTITIONED

  12:MERGE
  |
  6:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B

PLAN FRAGMENT 5
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 14
    UNPARTITIONED

  16:MERGE
  |
  4:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B

PLAN FRAGMENT 6
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 14
    UNPARTITIONED

  15:MERGE
  |
  3:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B

PLAN FRAGMENT 7
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 18
    UNPARTITIONED

  19:MERGE
  |
  1:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B
---- SCANRANGELOCATIONS
NODE 1:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 3:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 4:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=2/090201.txt 0:115
NODE 6:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=2/090201.txt 0:115
NODE 7:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=3/090301.txt 0:115
====
// Complex union unnesting: Partially unnestable up to 1st level
select * from functional.alltypestiny where year=2009 and month=1
union distinct
  (select * from functional.alltypestiny where year=2009 and month=1
   union distinct
     (select * from functional.alltypestiny where year=2009 and month=2
      union all
        (select * from functional.alltypestiny where year=2009 and month=2
         union distinct
         (select * from functional.alltypestiny where year=2009 and month=3)
         order by 3 limit 3)))
---- PLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  9:AGGREGATE (finalize)
  |  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
  |
  0:MERGE
  |
  |----8:TOP-N
  |    |  order by: tinyint_col ASC
  |    |  limit: 3
  |    |
  |    7:AGGREGATE (finalize)
  |    |  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
  |    |
  |    4:MERGE
  |    |
  |    |----6:SCAN HDFS
  |    |       table=functional.alltypestiny #partitions=1/4 size=115B
  |    |
  |    5:SCAN HDFS
  |       table=functional.alltypestiny #partitions=1/4 size=115B
  |
  |----3:SCAN HDFS
  |       table=functional.alltypestiny #partitions=1/4 size=115B
  |
  |----2:SCAN HDFS
  |       table=functional.alltypestiny #partitions=1/4 size=115B
  |
  1:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B
---- DISTRIBUTEDPLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  9:AGGREGATE (finalize)
  |  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
  |
  13:EXCHANGE

PLAN FRAGMENT 1
  PARTITION: UNPARTITIONED

  STREAM DATA SINK
    EXCHANGE ID: 13
    UNPARTITIONED

  17:MERGE
  |
  8:TOP-N
  |  order by: tinyint_col ASC
  |  limit: 3
  |
  7:AGGREGATE (finalize)
  |  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
  |
  10:EXCHANGE

PLAN FRAGMENT 2
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 10
    UNPARTITIONED

  12:MERGE
  |
  6:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B

PLAN FRAGMENT 3
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 10
    UNPARTITIONED

  11:MERGE
  |
  5:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B

PLAN FRAGMENT 4
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 13
    UNPARTITIONED

  16:MERGE
  |
  3:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B

PLAN FRAGMENT 5
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 13
    UNPARTITIONED

  15:MERGE
  |
  2:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B

PLAN FRAGMENT 6
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 13
    UNPARTITIONED

  14:MERGE
  |
  1:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B
---- SCANRANGELOCATIONS
NODE 1:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 2:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 3:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=2/090201.txt 0:115
NODE 5:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=2/090201.txt 0:115
NODE 6:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=3/090301.txt 0:115
====
// Complex union unnesting: Multiple nested unions to test all rules in a single query
select * from functional.alltypestiny where year=2009 and month=1
union distinct
  (select * from functional.alltypestiny where year=2009 and month=1
   union all
   select * from functional.alltypestiny where year=2009 and month=2)
union distinct
  (select * from functional.alltypestiny where year=2009 and month=2
   union all
   (select * from functional.alltypestiny where year=2009 and month=3)
   order by 3 limit 3)
union all
  (select * from functional.alltypestiny where year=2009 and month=3
   union all
   select * from functional.alltypestiny where year=2009 and month=4)
union all
  (select * from functional.alltypestiny where year=2009 and month=4
   union all
   (select * from functional.alltypestiny where year=2009 and month=5)
   order by 3 limit 3)
---- PLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  9:MERGE
  |
  |----8:AGGREGATE (finalize)
  |    |  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
  |    |
  |    0:MERGE
  |    |
  |    |----7:TOP-N
  |    |    |  order by: tinyint_col ASC
  |    |    |  limit: 3
  |    |    |
  |    |    4:MERGE
  |    |    |
  |    |    |----6:SCAN HDFS
  |    |    |       table=functional.alltypestiny #partitions=1/4 size=115B
  |    |    |
  |    |    5:SCAN HDFS
  |    |       table=functional.alltypestiny #partitions=1/4 size=115B
  |    |
  |    |----3:SCAN HDFS
  |    |       table=functional.alltypestiny #partitions=1/4 size=115B
  |    |
  |    |----2:SCAN HDFS
  |    |       table=functional.alltypestiny #partitions=1/4 size=115B
  |    |
  |    1:SCAN HDFS
  |       table=functional.alltypestiny #partitions=1/4 size=115B
  |
  |----15:TOP-N
  |    |  order by: tinyint_col ASC
  |    |  limit: 3
  |    |
  |    12:MERGE
  |    |
  |    |----14:SCAN HDFS
  |    |       table=functional.alltypestiny #partitions=0/4 size=0B
  |    |
  |    13:SCAN HDFS
  |       table=functional.alltypestiny #partitions=1/4 size=115B
  |
  |----11:SCAN HDFS
  |       table=functional.alltypestiny #partitions=1/4 size=115B
  |
  10:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B
---- DISTRIBUTEDPLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  27:EXCHANGE

PLAN FRAGMENT 1
  PARTITION: UNPARTITIONED

  STREAM DATA SINK
    EXCHANGE ID: 27
    UNPARTITIONED

  31:MERGE
  |
  8:AGGREGATE (finalize)
  |  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
  |
  22:EXCHANGE

PLAN FRAGMENT 2
  PARTITION: UNPARTITIONED

  STREAM DATA SINK
    EXCHANGE ID: 22
    UNPARTITIONED

  26:MERGE
  |
  7:TOP-N
  |  order by: tinyint_col ASC
  |  limit: 3
  |
  19:EXCHANGE

PLAN FRAGMENT 3
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 19
    UNPARTITIONED

  21:MERGE
  |
  6:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B

PLAN FRAGMENT 4
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 19
    UNPARTITIONED

  20:MERGE
  |
  5:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B

PLAN FRAGMENT 5
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 22
    UNPARTITIONED

  25:MERGE
  |
  3:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B

PLAN FRAGMENT 6
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 22
    UNPARTITIONED

  24:MERGE
  |
  2:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B

PLAN FRAGMENT 7
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 22
    UNPARTITIONED

  23:MERGE
  |
  1:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B

PLAN FRAGMENT 8
  PARTITION: UNPARTITIONED

  STREAM DATA SINK
    EXCHANGE ID: 27
    UNPARTITIONED

  30:MERGE
  |
  15:TOP-N
  |  order by: tinyint_col ASC
  |  limit: 3
  |
  16:EXCHANGE

PLAN FRAGMENT 9
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 16
    UNPARTITIONED

  18:MERGE
  |
  14:SCAN HDFS
     table=functional.alltypestiny #partitions=0/4 size=0B

PLAN FRAGMENT 10
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 16
    UNPARTITIONED

  17:MERGE
  |
  13:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B

PLAN FRAGMENT 11
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 27
    UNPARTITIONED

  29:MERGE
  |
  11:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B

PLAN FRAGMENT 12
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 27
    UNPARTITIONED

  28:MERGE
  |
  10:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B
---- SCANRANGELOCATIONS
NODE 1:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 2:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 3:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=2/090201.txt 0:115
NODE 5:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=2/090201.txt 0:115
NODE 6:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=3/090301.txt 0:115
NODE 10:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=3/090301.txt 0:115
NODE 11:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=4/090401.txt 0:115
NODE 13:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=4/090401.txt 0:115
NODE 14:
====
// UNION ALL in subquery
select x.* from
  (select * from functional.alltypestiny where year=2009 and month=1
   union all
   select * from functional.alltypestiny where year=2009 and month=1) x
union all
(select * from functional.alltypestiny where year=2009 and month=2)
order by 3 limit 5
---- PLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  5:TOP-N
  |  order by: tinyint_col ASC
  |  limit: 5
  |
  0:MERGE
  |
  |----4:SCAN HDFS
  |       table=functional.alltypestiny #partitions=1/4 size=115B
  |
  1:MERGE
  |
  |----3:SCAN HDFS
  |       table=functional.alltypestiny #partitions=1/4 size=115B
  |
  2:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B
---- DISTRIBUTEDPLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  5:TOP-N
  |  order by: tinyint_col ASC
  |  limit: 5
  |
  9:EXCHANGE

PLAN FRAGMENT 1
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 9
    UNPARTITIONED

  11:MERGE
  |
  4:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B

PLAN FRAGMENT 2
  PARTITION: UNPARTITIONED

  STREAM DATA SINK
    EXCHANGE ID: 9
    UNPARTITIONED

  10:MERGE
  |
  6:EXCHANGE

PLAN FRAGMENT 3
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 6
    UNPARTITIONED

  8:MERGE
  |
  3:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B

PLAN FRAGMENT 4
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 6
    UNPARTITIONED

  7:MERGE
  |
  2:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B
---- SCANRANGELOCATIONS
NODE 2:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 3:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 4:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=2/090201.txt 0:115
====
// UNION DISTINCT in subquery
select x.* from
  (select * from functional.alltypestiny where year=2009 and month=1
   union distinct
   select * from functional.alltypestiny where year=2009 and month=1) x
union distinct
(select * from functional.alltypestiny where year=2009 and month=2)
order by 3 limit 3
---- PLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  7:TOP-N
  |  order by: tinyint_col ASC
  |  limit: 3
  |
  6:AGGREGATE (finalize)
  |  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
  |
  0:MERGE
  |
  |----5:SCAN HDFS
  |       table=functional.alltypestiny #partitions=1/4 size=115B
  |
  4:AGGREGATE (finalize)
  |  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
  |
  1:MERGE
  |
  |----3:SCAN HDFS
  |       table=functional.alltypestiny #partitions=1/4 size=115B
  |
  2:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B
---- DISTRIBUTEDPLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  7:TOP-N
  |  order by: tinyint_col ASC
  |  limit: 3
  |
  6:AGGREGATE (finalize)
  |  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
  |
  11:EXCHANGE

PLAN FRAGMENT 1
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 11
    UNPARTITIONED

  13:MERGE
  |
  5:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B

PLAN FRAGMENT 2
  PARTITION: UNPARTITIONED

  STREAM DATA SINK
    EXCHANGE ID: 11
    UNPARTITIONED

  12:MERGE
  |
  4:AGGREGATE (finalize)
  |  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
  |
  8:EXCHANGE

PLAN FRAGMENT 3
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 8
    UNPARTITIONED

  10:MERGE
  |
  3:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B

PLAN FRAGMENT 4
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 8
    UNPARTITIONED

  9:MERGE
  |
  2:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B
---- SCANRANGELOCATIONS
NODE 2:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 3:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 5:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=2/090201.txt 0:115
====
// UNION ALL in subquery with a WHERE condition in the outer select.
select x.* from
  (select int_col, bool_col, count(*) as count_col
   from functional.alltypestiny where year=2009 and month=1 group by 1, 2
   union all
   select int_col, bool_col, count(*) as count_col
   from functional.alltypestiny where year=2009 and month=1 group by 1, 2) x
where x.int_col < 5 and x.bool_col = false
---- PLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  0:MERGE
  |
  |----4:AGGREGATE (finalize)
  |    |  output: COUNT(*)
  |    |  group by: int_col, bool_col
  |    |
  |    3:SCAN HDFS
  |       table=functional.alltypestiny #partitions=1/4 size=115B
  |       predicates: functional.alltypestiny.int_col < 5, functional.alltypestiny.bool_col = FALSE
  |
  2:AGGREGATE (finalize)
  |  output: COUNT(*)
  |  group by: int_col, bool_col
  |
  1:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B
     predicates: functional.alltypestiny.int_col < 5, functional.alltypestiny.bool_col = FALSE
---- DISTRIBUTEDPLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  9:EXCHANGE

PLAN FRAGMENT 1
  PARTITION: HASH_PARTITIONED: int_col, bool_col

  STREAM DATA SINK
    EXCHANGE ID: 9
    UNPARTITIONED

  11:MERGE
  |
  8:AGGREGATE (merge finalize)
  |  output: SUM(COUNT(*))
  |  group by: int_col, bool_col
  |
  7:EXCHANGE

PLAN FRAGMENT 2
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 7
    HASH_PARTITIONED: int_col, bool_col

  4:AGGREGATE
  |  output: COUNT(*)
  |  group by: int_col, bool_col
  |
  3:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B
     predicates: functional.alltypestiny.int_col < 5, functional.alltypestiny.bool_col = FALSE

PLAN FRAGMENT 3
  PARTITION: HASH_PARTITIONED: int_col, bool_col

  STREAM DATA SINK
    EXCHANGE ID: 9
    UNPARTITIONED

  10:MERGE
  |
  6:AGGREGATE (merge finalize)
  |  output: SUM(COUNT(*))
  |  group by: int_col, bool_col
  |
  5:EXCHANGE

PLAN FRAGMENT 4
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 5
    HASH_PARTITIONED: int_col, bool_col

  2:AGGREGATE
  |  output: COUNT(*)
  |  group by: int_col, bool_col
  |
  1:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B
     predicates: functional.alltypestiny.int_col < 5, functional.alltypestiny.bool_col = FALSE
---- SCANRANGELOCATIONS
NODE 1:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
NODE 3:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypestiny/year=2009/month=1/090101.txt 0:115
====
// UNION ALL with only constant selects
select 1, 'a', NULL, 10.f
union all
select 2, 'b', NULL, 20.f
union all
select 3, 'c', NULL, 30.f
---- PLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  0:MERGE
     merging 3 SELECT CONSTANT
---- DISTRIBUTEDPLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  0:MERGE
     merging 3 SELECT CONSTANT
====
// UNION DISTINCT with only constant selects
select 1, 'a', NULL, 10.0f
union distinct
select 2, 'b', NULL, 20.0f
union distinct
select 3, 'c', NULL, 30.0f
---- PLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  1:AGGREGATE (finalize)
  |  group by: 1, 'a', null, f
  |
  0:MERGE
     merging 3 SELECT CONSTANT
---- DISTRIBUTEDPLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  1:AGGREGATE (finalize)
  |  group by: 1, 'a', null, f
  |
  0:MERGE
     merging 3 SELECT CONSTANT
====
// UNION ALL/DISTINCT with mixed constant selects and non-constant selects
select 1, 'a', NULL, 10.f
union all
select int_col, string_col, bool_col, float_col from functional.alltypestiny
union distinct
select 3, 'c', NULL, 30.f
union all
select int_col, string_col, bool_col, float_col from functional.alltypestiny
---- PLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  3:MERGE
  |
  |----2:AGGREGATE (finalize)
  |    |  group by: 1, 'a', null, f
  |    |
  |    0:MERGE
  |    |  merging 2 SELECT CONSTANT
  |    |
  |    1:SCAN HDFS
  |       table=functional.alltypestiny #partitions=4/4 size=460B
  |
  4:SCAN HDFS
     table=functional.alltypestiny #partitions=4/4 size=460B
---- DISTRIBUTEDPLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  8:EXCHANGE

PLAN FRAGMENT 1
  PARTITION: UNPARTITIONED

  STREAM DATA SINK
    EXCHANGE ID: 8
    UNPARTITIONED

  10:MERGE
  |
  2:AGGREGATE (finalize)
  |  group by: 1, 'a', null, f
  |
  5:EXCHANGE

PLAN FRAGMENT 2
  PARTITION: UNPARTITIONED

  STREAM DATA SINK
    EXCHANGE ID: 5
    UNPARTITIONED

  7:MERGE
     merging 2 SELECT CONSTANT

PLAN FRAGMENT 3
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 5
    UNPARTITIONED

  6:MERGE
  |
  1:SCAN HDFS
     table=functional.alltypestiny #partitions=4/4 size=460B

PLAN FRAGMENT 4
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 8
    UNPARTITIONED

  9:MERGE
  |
  4:SCAN HDFS
     table=functional.alltypestiny #partitions=4/4 size=460B
====
// UNION ALL/DISTINCT with mixed constant selects and non-constant selects and nested unions
(select 500
 union all
 (select int_col from functional.alltypestiny where year=2009 and month=2
  order by 1 limit 3
  union all
  select 500)
)
union distinct
select int_col from functional.alltypestiny where year=2009 and month=1
union all
select 503
---- PLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  5:MERGE
  |  merging 1 SELECT CONSTANT
  |
  4:AGGREGATE (finalize)
  |  group by: 500
  |
  0:MERGE
  |  merging 2 SELECT CONSTANT
  |
  |----3:SCAN HDFS
  |       table=functional.alltypestiny #partitions=1/4 size=115B
  |
  2:TOP-N
  |  order by: int_col ASC
  |  limit: 3
  |
  1:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B
---- DISTRIBUTEDPLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  12:EXCHANGE

PLAN FRAGMENT 1
  PARTITION: UNPARTITIONED

  STREAM DATA SINK
    EXCHANGE ID: 12
    UNPARTITIONED

  14:MERGE
     merging 1 SELECT CONSTANT

PLAN FRAGMENT 2
  PARTITION: UNPARTITIONED

  STREAM DATA SINK
    EXCHANGE ID: 12
    UNPARTITIONED

  13:MERGE
  |
  4:AGGREGATE (finalize)
  |  group by: 500
  |
  8:EXCHANGE

PLAN FRAGMENT 3
  PARTITION: UNPARTITIONED

  STREAM DATA SINK
    EXCHANGE ID: 8
    UNPARTITIONED

  11:MERGE
     merging 2 SELECT CONSTANT

PLAN FRAGMENT 4
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 8
    UNPARTITIONED

  10:MERGE
  |
  3:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B

PLAN FRAGMENT 5
  PARTITION: UNPARTITIONED

  STREAM DATA SINK
    EXCHANGE ID: 8
    UNPARTITIONED

  9:MERGE
  |
  7:TOP-N
  |  order by: int_col ASC
  |  limit: 3
  |
  6:EXCHANGE

PLAN FRAGMENT 6
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 6
    UNPARTITIONED

  2:TOP-N
  |  order by: int_col ASC
  |  limit: 3
  |
  1:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B
====
// UNION ALL with only values statements
values(1, 'a', NULL, 10.f)
union all
values(2, 'b', NULL, 20.f)
union all
values(3, 'c', NULL, 30.f)
---- PLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  0:MERGE
     merging 3 SELECT CONSTANT
---- DISTRIBUTEDPLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  0:MERGE
     merging 3 SELECT CONSTANT
====
// UNION DISTINCT with only values statements
values(1, 'a', NULL, 10.f)
union distinct
values(2, 'b', NULL, 20.f)
union distinct
values(3, 'c', NULL, 30.f)
---- PLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  1:AGGREGATE (finalize)
  |  group by: 1, 'a', null, f
  |
  0:MERGE
     merging 3 SELECT CONSTANT
---- DISTRIBUTEDPLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  1:AGGREGATE (finalize)
  |  group by: 1, 'a', null, f
  |
  0:MERGE
     merging 3 SELECT CONSTANT
====
// UNION ALL/DISTINCT with mixed values statements and non-constant selects
values(1, 'a', NULL, 10.f)
union all
select int_col, string_col, bool_col, float_col from functional.alltypestiny
union distinct
values(3, 'c', NULL, 30.f)
union all
select int_col, string_col, bool_col, float_col from functional.alltypessmall
---- PLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  3:MERGE
  |
  |----2:AGGREGATE (finalize)
  |    |  group by: 1, 'a', null, f
  |    |
  |    0:MERGE
  |    |  merging 2 SELECT CONSTANT
  |    |
  |    1:SCAN HDFS
  |       table=functional.alltypestiny #partitions=4/4 size=460B
  |
  4:SCAN HDFS
     table=functional.alltypessmall #partitions=4/4 size=6.32KB
---- DISTRIBUTEDPLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  8:EXCHANGE

PLAN FRAGMENT 1
  PARTITION: UNPARTITIONED

  STREAM DATA SINK
    EXCHANGE ID: 8
    UNPARTITIONED

  10:MERGE
  |
  2:AGGREGATE (finalize)
  |  group by: 1, 'a', null, f
  |
  5:EXCHANGE

PLAN FRAGMENT 2
  PARTITION: UNPARTITIONED

  STREAM DATA SINK
    EXCHANGE ID: 5
    UNPARTITIONED

  7:MERGE
     merging 2 SELECT CONSTANT

PLAN FRAGMENT 3
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 5
    UNPARTITIONED

  6:MERGE
  |
  1:SCAN HDFS
     table=functional.alltypestiny #partitions=4/4 size=460B

PLAN FRAGMENT 4
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 8
    UNPARTITIONED

  9:MERGE
  |
  4:SCAN HDFS
     table=functional.alltypessmall #partitions=4/4 size=6.32KB
====
# all union output slots are being materialized even though none is referenced by
# the enclosing scope
select count(*) from (
  select id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col,
      double_col, date_string_col, string_col, timestamp_col, year, month
    from functional.alltypes
  union distinct
  select 0,true,0,0,0,0,cast(0 as float),0,'01/01/09','0',
      cast('2009-01-01 00:00:00' as timestamp),2009,1
  union distinct
  select id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col,
      double_col, date_string_col, string_col, timestamp_col, year, month
    from functional.alltypes
  union distinct
  select 1,false,1,1,1,10,cast(1.1 as float),10.1,'01/01/09','1',
      cast('2009-01-01 00:01:00' as timestamp),2009,1
  union distinct
  select 2,true,2,2,2,20,cast(2.2 as float),20.2,'01/01/09','2',
      cast('2009-01-01 00:02:00.10' as timestamp),2009,1
) x
---- PLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  4:AGGREGATE (finalize)
  |  output: COUNT(*)
  |
  3:AGGREGATE (finalize)
  |  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
  |
  0:MERGE
  |  merging 3 SELECT CONSTANT
  |
  |----2:SCAN HDFS
  |       table=functional.alltypes #partitions=24/24 size=478.45KB
  |
  1:SCAN HDFS
     table=functional.alltypes #partitions=24/24 size=478.45KB
---- DISTRIBUTEDPLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  4:AGGREGATE (finalize)
  |  output: COUNT(*)
  |
  3:AGGREGATE (finalize)
  |  group by: id, bool_col, tinyint_col, smallint_col, int_col, bigint_col, float_col, double_col, date_string_col, string_col, timestamp_col, year, month
  |
  5:EXCHANGE

PLAN FRAGMENT 1
  PARTITION: UNPARTITIONED

  STREAM DATA SINK
    EXCHANGE ID: 5
    UNPARTITIONED

  8:MERGE
     merging 3 SELECT CONSTANT

PLAN FRAGMENT 2
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 5
    UNPARTITIONED

  7:MERGE
  |
  2:SCAN HDFS
     table=functional.alltypes #partitions=24/24 size=478.45KB

PLAN FRAGMENT 3
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 5
    UNPARTITIONED

  6:MERGE
  |
  1:SCAN HDFS
     table=functional.alltypes #partitions=24/24 size=478.45KB
====
// UNION ALL in subquery with a WHERE condition in the outer select;
// Where clause conjuncts are used as scan predicates and for partition pruning.
select x.int_col, x.bool_col, x.month from
  (select * from functional.alltypestiny where year=2009 
   union all
   select * from functional.alltypestiny where year=2009) x
where x.int_col < 5 and x.bool_col = false and x.month = 1
---- PLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  0:MERGE
  |
  |----2:SCAN HDFS
  |       table=functional.alltypestiny #partitions=1/4 size=115B
  |       predicates: functional.alltypestiny.bool_col = FALSE, functional.alltypestiny.int_col < 5
  |
  1:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B
     predicates: functional.alltypestiny.bool_col = FALSE, functional.alltypestiny.int_col < 5
---- DISTRIBUTEDPLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  3:EXCHANGE

PLAN FRAGMENT 1
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 3
    UNPARTITIONED

  5:MERGE
  |
  2:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B
     predicates: functional.alltypestiny.bool_col = FALSE, functional.alltypestiny.int_col < 5

PLAN FRAGMENT 2
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 3
    UNPARTITIONED

  4:MERGE
  |
  1:SCAN HDFS
     table=functional.alltypestiny #partitions=1/4 size=115B
     predicates: functional.alltypestiny.bool_col = FALSE, functional.alltypestiny.int_col < 5
====
