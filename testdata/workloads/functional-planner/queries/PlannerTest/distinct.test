# distinct *
select distinct *
from functional.testtbl
---- PLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  1:AGGREGATE
  |  group by: functional.testtbl.id, functional.testtbl.name, functional.testtbl.zip
  |  tuple ids: 1 
  |  
  0:SCAN HDFS
     table=functional.testtbl #partitions=0 size=0B
     tuple ids: 0 
---- DISTRIBUTEDPLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  4:EXCHANGE
     tuple ids: 1 

PLAN FRAGMENT 1
  PARTITION: HASH_PARTITIONED: <slot 3>, <slot 4>, <slot 5>

  STREAM DATA SINK
    EXCHANGE ID: 4
    UNPARTITIONED

  3:AGGREGATE
  |  group by: <slot 3>, <slot 4>, <slot 5>
  |  tuple ids: 1 
  |  
  2:EXCHANGE
     tuple ids: 1 

PLAN FRAGMENT 2
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 2
    HASH_PARTITIONED: <slot 3>, <slot 4>, <slot 5>

  1:AGGREGATE
  |  group by: functional.testtbl.id, functional.testtbl.name, functional.testtbl.zip
  |  tuple ids: 1 
  |  
  0:SCAN HDFS
     table=functional.testtbl #partitions=0 size=0B
     tuple ids: 0 
---- SCANRANGELOCATIONS
NODE 0:
====
# distinct w/ explicit select list
select distinct id, zip
from functional.testtbl
---- PLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  1:AGGREGATE
  |  group by: id, zip
  |  tuple ids: 1 
  |  
  0:SCAN HDFS
     table=functional.testtbl #partitions=0 size=0B
     tuple ids: 0 
---- DISTRIBUTEDPLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  4:EXCHANGE
     tuple ids: 1 

PLAN FRAGMENT 1
  PARTITION: HASH_PARTITIONED: <slot 2>, <slot 3>

  STREAM DATA SINK
    EXCHANGE ID: 4
    UNPARTITIONED

  3:AGGREGATE
  |  group by: <slot 2>, <slot 3>
  |  tuple ids: 1 
  |  
  2:EXCHANGE
     tuple ids: 1 

PLAN FRAGMENT 2
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 2
    HASH_PARTITIONED: <slot 2>, <slot 3>

  1:AGGREGATE
  |  group by: id, zip
  |  tuple ids: 1 
  |  
  0:SCAN HDFS
     table=functional.testtbl #partitions=0 size=0B
     tuple ids: 0 
---- SCANRANGELOCATIONS
NODE 0:
====
# count(distinct)
select count(distinct id, zip)
from functional.testtbl
---- PLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  2:AGGREGATE
  |  output: COUNT(if(<slot 2> IS NULL, NULL, <slot 3>))
  |  group by: 
  |  tuple ids: 2 
  |  
  1:AGGREGATE
  |  group by: id, zip
  |  tuple ids: 1 
  |  
  0:SCAN HDFS
     table=functional.testtbl #partitions=0 size=0B
     tuple ids: 0 
---- DISTRIBUTEDPLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  6:AGGREGATE
  |  output: SUM(<slot 4>)
  |  group by: 
  |  tuple ids: 2 
  |  
  5:EXCHANGE
     tuple ids: 2 

PLAN FRAGMENT 1
  PARTITION: HASH_PARTITIONED: <slot 2>, <slot 3>

  STREAM DATA SINK
    EXCHANGE ID: 5
    UNPARTITIONED

  2:AGGREGATE
  |  output: COUNT(if(<slot 2> IS NULL, NULL, <slot 3>))
  |  group by: 
  |  tuple ids: 2 
  |  
  4:AGGREGATE
  |  group by: <slot 2>, <slot 3>
  |  tuple ids: 1 
  |  
  3:EXCHANGE
     tuple ids: 1 

PLAN FRAGMENT 2
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 3
    HASH_PARTITIONED: <slot 2>, <slot 3>

  1:AGGREGATE
  |  group by: id, zip
  |  tuple ids: 1 
  |  
  0:SCAN HDFS
     table=functional.testtbl #partitions=0 size=0B
     tuple ids: 0 
---- SCANRANGELOCATIONS
NODE 0:
====
# count(distinct) w/ grouping
select tinyint_col, count(distinct int_col, bigint_col)
from functional.alltypesagg
group by 1
---- PLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  2:AGGREGATE
  |  output: COUNT(if(<slot 4> IS NULL, NULL, <slot 5>))
  |  group by: <slot 3>
  |  tuple ids: 2 
  |  
  1:AGGREGATE
  |  group by: tinyint_col, int_col, bigint_col
  |  tuple ids: 1 
  |  
  0:SCAN HDFS
     table=functional.alltypesagg #partitions=10 size=743.67KB
     tuple ids: 0 
---- DISTRIBUTEDPLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  5:EXCHANGE
     tuple ids: 2 

PLAN FRAGMENT 1
  PARTITION: HASH_PARTITIONED: <slot 3>

  STREAM DATA SINK
    EXCHANGE ID: 5
    UNPARTITIONED

  2:AGGREGATE
  |  output: COUNT(if(<slot 4> IS NULL, NULL, <slot 5>))
  |  group by: <slot 3>
  |  tuple ids: 2 
  |  
  4:AGGREGATE
  |  group by: <slot 3>, <slot 4>, <slot 5>
  |  tuple ids: 1 
  |  
  3:EXCHANGE
     tuple ids: 1 

PLAN FRAGMENT 2
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 3
    HASH_PARTITIONED: <slot 3>

  1:AGGREGATE
  |  group by: tinyint_col, int_col, bigint_col
  |  tuple ids: 1 
  |  
  0:SCAN HDFS
     table=functional.alltypesagg #partitions=10 size=743.67KB
     tuple ids: 0 
---- SCANRANGELOCATIONS
NODE 0:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=1/100101.txt 0:75153
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=10/100110.txt 0:76263
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=2/100102.txt 0:76263
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=3/100103.txt 0:76263
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=4/100104.txt 0:76263
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=5/100105.txt 0:76263
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=6/100106.txt 0:76263
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=7/100107.txt 0:76263
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=8/100108.txt 0:76263
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=9/100109.txt 0:76263
====
# count(distinct) and sum(distinct) w/ grouping
select tinyint_col, count(distinct int_col), sum(distinct int_col)
from functional.alltypesagg
group by 1
---- PLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  2:AGGREGATE
  |  output: COUNT(<slot 3>), SUM(<slot 3>)
  |  group by: <slot 2>
  |  tuple ids: 2 
  |  
  1:AGGREGATE
  |  group by: tinyint_col, int_col
  |  tuple ids: 1 
  |  
  0:SCAN HDFS
     table=functional.alltypesagg #partitions=10 size=743.67KB
     tuple ids: 0 
---- DISTRIBUTEDPLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  5:EXCHANGE
     tuple ids: 2 

PLAN FRAGMENT 1
  PARTITION: HASH_PARTITIONED: <slot 2>

  STREAM DATA SINK
    EXCHANGE ID: 5
    UNPARTITIONED

  2:AGGREGATE
  |  output: COUNT(<slot 3>), SUM(<slot 3>)
  |  group by: <slot 2>
  |  tuple ids: 2 
  |  
  4:AGGREGATE
  |  group by: <slot 2>, <slot 3>
  |  tuple ids: 1 
  |  
  3:EXCHANGE
     tuple ids: 1 

PLAN FRAGMENT 2
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 3
    HASH_PARTITIONED: <slot 2>

  1:AGGREGATE
  |  group by: tinyint_col, int_col
  |  tuple ids: 1 
  |  
  0:SCAN HDFS
     table=functional.alltypesagg #partitions=10 size=743.67KB
     tuple ids: 0 
---- SCANRANGELOCATIONS
NODE 0:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=1/100101.txt 0:75153
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=10/100110.txt 0:76263
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=2/100102.txt 0:76263
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=3/100103.txt 0:76263
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=4/100104.txt 0:76263
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=5/100105.txt 0:76263
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=6/100106.txt 0:76263
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=7/100107.txt 0:76263
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=8/100108.txt 0:76263
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=9/100109.txt 0:76263
====
# count(distinct) and sum(distinct) w/ grouping; distinct in min() and max()
# is ignored
select tinyint_col, count(distinct int_col),
min(distinct smallint_col), max(distinct string_col)
from functional.alltypesagg group by 1
---- PLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  2:AGGREGATE
  |  output: COUNT(<slot 5>), MIN(<slot 6>), MAX(<slot 7>)
  |  group by: <slot 4>
  |  tuple ids: 2 
  |  
  1:AGGREGATE
  |  output: MIN(smallint_col), MAX(string_col)
  |  group by: tinyint_col, int_col
  |  tuple ids: 1 
  |  
  0:SCAN HDFS
     table=functional.alltypesagg #partitions=10 size=743.67KB
     tuple ids: 0 
---- DISTRIBUTEDPLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  5:EXCHANGE
     tuple ids: 2 

PLAN FRAGMENT 1
  PARTITION: HASH_PARTITIONED: <slot 4>

  STREAM DATA SINK
    EXCHANGE ID: 5
    UNPARTITIONED

  2:AGGREGATE
  |  output: COUNT(<slot 5>), MIN(<slot 6>), MAX(<slot 7>)
  |  group by: <slot 4>
  |  tuple ids: 2 
  |  
  4:AGGREGATE
  |  output: MIN(<slot 6>), MAX(<slot 7>)
  |  group by: <slot 4>, <slot 5>
  |  tuple ids: 1 
  |  
  3:EXCHANGE
     tuple ids: 1 

PLAN FRAGMENT 2
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 3
    HASH_PARTITIONED: <slot 4>

  1:AGGREGATE
  |  output: MIN(smallint_col), MAX(string_col)
  |  group by: tinyint_col, int_col
  |  tuple ids: 1 
  |  
  0:SCAN HDFS
     table=functional.alltypesagg #partitions=10 size=743.67KB
     tuple ids: 0 
---- SCANRANGELOCATIONS
NODE 0:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=1/100101.txt 0:75153
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=10/100110.txt 0:76263
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=2/100102.txt 0:76263
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=3/100103.txt 0:76263
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=4/100104.txt 0:76263
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=5/100105.txt 0:76263
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=6/100106.txt 0:76263
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=7/100107.txt 0:76263
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=8/100108.txt 0:76263
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=9/100109.txt 0:76263
====
# aggregate fns with and without distinct
select tinyint_col, count(distinct int_col), count(*), sum(distinct int_col),
sum(int_col), min(smallint_col), max(bigint_col)
from functional.alltypesagg group by 1
---- PLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  2:AGGREGATE
  |  output: COUNT(<slot 5>), SUM(<slot 5>), SUM(<slot 6>), SUM(<slot 7>), MIN(<slot 8>), MAX(<slot 9>)
  |  group by: <slot 4>
  |  tuple ids: 2 
  |  
  1:AGGREGATE
  |  output: COUNT(*), SUM(int_col), MIN(smallint_col), MAX(bigint_col)
  |  group by: tinyint_col, int_col
  |  tuple ids: 1 
  |  
  0:SCAN HDFS
     table=functional.alltypesagg #partitions=10 size=743.67KB
     tuple ids: 0 
---- DISTRIBUTEDPLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  5:EXCHANGE
     tuple ids: 2 

PLAN FRAGMENT 1
  PARTITION: HASH_PARTITIONED: <slot 4>

  STREAM DATA SINK
    EXCHANGE ID: 5
    UNPARTITIONED

  2:AGGREGATE
  |  output: COUNT(<slot 5>), SUM(<slot 5>), SUM(<slot 6>), SUM(<slot 7>), MIN(<slot 8>), MAX(<slot 9>)
  |  group by: <slot 4>
  |  tuple ids: 2 
  |  
  4:AGGREGATE
  |  output: SUM(<slot 6>), SUM(<slot 7>), MIN(<slot 8>), MAX(<slot 9>)
  |  group by: <slot 4>, <slot 5>
  |  tuple ids: 1 
  |  
  3:EXCHANGE
     tuple ids: 1 

PLAN FRAGMENT 2
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 3
    HASH_PARTITIONED: <slot 4>

  1:AGGREGATE
  |  output: COUNT(*), SUM(int_col), MIN(smallint_col), MAX(bigint_col)
  |  group by: tinyint_col, int_col
  |  tuple ids: 1 
  |  
  0:SCAN HDFS
     table=functional.alltypesagg #partitions=10 size=743.67KB
     tuple ids: 0 
---- SCANRANGELOCATIONS
NODE 0:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=1/100101.txt 0:75153
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=10/100110.txt 0:76263
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=2/100102.txt 0:76263
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=3/100103.txt 0:76263
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=4/100104.txt 0:76263
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=5/100105.txt 0:76263
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=6/100106.txt 0:76263
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=7/100107.txt 0:76263
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=8/100108.txt 0:76263
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=9/100109.txt 0:76263
====
