---- QUERY
# Basic test with a single with-clause view.
with t as (select int_col x, bigint_col y from functional.alltypes) select x, y from t
---- PLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  0:SCAN HDFS
     table=functional.alltypes #partitions=24 size=478.45KB
     tuple ids: 0
---- DISTRIBUTEDPLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  1:EXCHANGE
     tuple ids: 0

PLAN FRAGMENT 1
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 1
    UNPARTITIONED

  0:SCAN HDFS
     table=functional.alltypes #partitions=24 size=478.45KB
     tuple ids: 0
====
---- QUERY
# Basic test with a single with-clause view that references a catalog view.
with t as (select int_col x, bigint_col y from functional.alltypes_view)
select x, y from t
---- PLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  0:SCAN HDFS
     table=functional.alltypes #partitions=24 size=478.45KB
     tuple ids: 0
---- DISTRIBUTEDPLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  1:EXCHANGE
     tuple ids: 0

PLAN FRAGMENT 1
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 1
    UNPARTITIONED

  0:SCAN HDFS
     table=functional.alltypes #partitions=24 size=478.45KB
     tuple ids: 0
====
---- QUERY
# Multiple views in with-clause. Only one view is used.
with t1 as (select int_col x, bigint_col y from functional.alltypes),
t2 as (select 1 x , 10 y), t3 as (values(2 x , 20 y), (3, 30))
select x, y from t2
---- PLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  0:MERGE
     merging 1 SELECT CONSTANT
     tuple ids: 0
---- DISTRIBUTEDPLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  0:MERGE
     merging 1 SELECT CONSTANT
     tuple ids: 0
====
---- QUERY
# Multiple views in with-clause. All views are used in a union.
with t1 as (select int_col x, bigint_col y from functional.alltypes),
t2 as (select 1 x , 10 y), t3 as (values(2 x , 20 y), (3, 30))
select * from t1 union all select * from t2 union all select * from t3
---- PLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  0:MERGE
  |  tuple ids: 5
  |
  |----2:MERGE
  |       merging 1 SELECT CONSTANT
  |       tuple ids: 2
  |
  |----3:MERGE
  |       merging 2 SELECT CONSTANT
  |       tuple ids: 3
  |
  1:SCAN HDFS
     table=functional.alltypes #partitions=24 size=478.45KB
     tuple ids: 0
---- DISTRIBUTEDPLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  4:EXCHANGE
     tuple ids: 5

PLAN FRAGMENT 1
  PARTITION: UNPARTITIONED

  STREAM DATA SINK
    EXCHANGE ID: 4
    UNPARTITIONED

  7:MERGE
  |  tuple ids: 5
  |
  3:MERGE
     merging 2 SELECT CONSTANT
     tuple ids: 3

PLAN FRAGMENT 2
  PARTITION: UNPARTITIONED

  STREAM DATA SINK
    EXCHANGE ID: 4
    UNPARTITIONED

  6:MERGE
  |  tuple ids: 5
  |
  2:MERGE
     merging 1 SELECT CONSTANT
     tuple ids: 2

PLAN FRAGMENT 3
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 4
    UNPARTITIONED

  5:MERGE
  |  tuple ids: 5
  |
  1:SCAN HDFS
     table=functional.alltypes #partitions=24 size=478.45KB
     tuple ids: 0
====
---- QUERY
# Multiple views in with-clause. All views are used in a join.
with t1 as (select int_col x, bigint_col y from functional.alltypes),
t2 as (select int_col x, bigint_col y from functional.alltypestiny),
t3 as (select int_col x, bigint_col y from functional.alltypessmall)
select * from t1, t2, t3 where t1.x = t2.x and t2.x = t3.x
---- PLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  4:HASH JOIN
  |  join op: INNER JOIN
  |  hash predicates:
  |    int_col = int_col
  |  tuple ids: 0 2 4
  |
  |----3:SCAN HDFS
  |       table=functional.alltypessmall #partitions=4 size=6.32KB compact
  |       tuple ids: 4
  |
  2:HASH JOIN
  |  join op: INNER JOIN
  |  hash predicates:
  |    int_col = int_col
  |  tuple ids: 0 2
  |
  |----1:SCAN HDFS
  |       table=functional.alltypestiny #partitions=4 size=460B compact
  |       tuple ids: 2
  |
  0:SCAN HDFS
     table=functional.alltypes #partitions=24 size=478.45KB
     tuple ids: 0
---- DISTRIBUTEDPLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  7:EXCHANGE
     tuple ids: 0 2 4

PLAN FRAGMENT 1
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 7
    UNPARTITIONED

  4:HASH JOIN
  |  join op: INNER JOIN (BROADCAST)
  |  hash predicates:
  |    int_col = int_col
  |  tuple ids: 0 2 4
  |
  |----6:EXCHANGE
  |       tuple ids: 4
  |
  2:HASH JOIN
  |  join op: INNER JOIN (BROADCAST)
  |  hash predicates:
  |    int_col = int_col
  |  tuple ids: 0 2
  |
  |----5:EXCHANGE
  |       tuple ids: 2
  |
  0:SCAN HDFS
     table=functional.alltypes #partitions=24 size=478.45KB
     tuple ids: 0

PLAN FRAGMENT 2
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 6
    UNPARTITIONED

  3:SCAN HDFS
     table=functional.alltypessmall #partitions=4 size=6.32KB
     tuple ids: 4

PLAN FRAGMENT 3
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 5
    UNPARTITIONED

  1:SCAN HDFS
     table=functional.alltypestiny #partitions=4 size=460B
     tuple ids: 2
====
---- QUERY
# Self-join of with-clause table to make sure the on clause is properly set
# in the cloned inline-view instances.
with t as (select int_col x, bigint_col y from functional.alltypestiny)
select * from t t1 inner join t t2 on (t1.x = t2.x) inner join t t3 on (t2.x = t3.x)
---- PLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  4:HASH JOIN
  |  join op: INNER JOIN
  |  hash predicates:
  |    int_col = int_col
  |  tuple ids: 0 2 4
  |
  |----3:SCAN HDFS
  |       table=functional.alltypestiny #partitions=4 size=460B compact
  |       tuple ids: 4
  |
  2:HASH JOIN
  |  join op: INNER JOIN
  |  hash predicates:
  |    int_col = int_col
  |  tuple ids: 0 2
  |
  |----1:SCAN HDFS
  |       table=functional.alltypestiny #partitions=4 size=460B compact
  |       tuple ids: 2
  |
  0:SCAN HDFS
     table=functional.alltypestiny #partitions=4 size=460B
     tuple ids: 0
---- DISTRIBUTEDPLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  8:EXCHANGE
     tuple ids: 0 2 4

PLAN FRAGMENT 1
  PARTITION: HASH_PARTITIONED: int_col

  STREAM DATA SINK
    EXCHANGE ID: 8
    UNPARTITIONED

  4:HASH JOIN
  |  join op: INNER JOIN (BROADCAST)
  |  hash predicates:
  |    int_col = int_col
  |  tuple ids: 0 2 4
  |
  |----7:EXCHANGE
  |       tuple ids: 4
  |
  2:HASH JOIN
  |  join op: INNER JOIN (PARTITIONED)
  |  hash predicates:
  |    int_col = int_col
  |  tuple ids: 0 2
  |
  |----6:EXCHANGE
  |       tuple ids: 2
  |
  5:EXCHANGE
     tuple ids: 0

PLAN FRAGMENT 2
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 7
    UNPARTITIONED

  3:SCAN HDFS
     table=functional.alltypestiny #partitions=4 size=460B
     tuple ids: 4

PLAN FRAGMENT 3
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 6
    HASH_PARTITIONED: int_col

  1:SCAN HDFS
     table=functional.alltypestiny #partitions=4 size=460B
     tuple ids: 2

PLAN FRAGMENT 4
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 5
    HASH_PARTITIONED: int_col

  0:SCAN HDFS
     table=functional.alltypestiny #partitions=4 size=460B
     tuple ids: 0
====
---- QUERY
# Self-join of with-clause table to make sure the using clause is properly set
# in the cloned inline-view instances.
with t as (select int_col x, bigint_col y from functional.alltypestiny)
select * from t t1 inner join t t2 using(x) inner join t t3 using(x)
---- PLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  4:HASH JOIN
  |  join op: INNER JOIN
  |  hash predicates:
  |    int_col = int_col
  |  tuple ids: 0 2 4
  |
  |----3:SCAN HDFS
  |       table=functional.alltypestiny #partitions=4 size=460B compact
  |       tuple ids: 4
  |
  2:HASH JOIN
  |  join op: INNER JOIN
  |  hash predicates:
  |    int_col = int_col
  |  tuple ids: 0 2
  |
  |----1:SCAN HDFS
  |       table=functional.alltypestiny #partitions=4 size=460B compact
  |       tuple ids: 2
  |
  0:SCAN HDFS
     table=functional.alltypestiny #partitions=4 size=460B
     tuple ids: 0
---- DISTRIBUTEDPLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  8:EXCHANGE
     tuple ids: 0 2 4

PLAN FRAGMENT 1
  PARTITION: HASH_PARTITIONED: int_col

  STREAM DATA SINK
    EXCHANGE ID: 8
    UNPARTITIONED

  4:HASH JOIN
  |  join op: INNER JOIN (BROADCAST)
  |  hash predicates:
  |    int_col = int_col
  |  tuple ids: 0 2 4
  |
  |----7:EXCHANGE
  |       tuple ids: 4
  |
  2:HASH JOIN
  |  join op: INNER JOIN (PARTITIONED)
  |  hash predicates:
  |    int_col = int_col
  |  tuple ids: 0 2
  |
  |----6:EXCHANGE
  |       tuple ids: 2
  |
  5:EXCHANGE
     tuple ids: 0

PLAN FRAGMENT 2
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 7
    UNPARTITIONED

  3:SCAN HDFS
     table=functional.alltypestiny #partitions=4 size=460B
     tuple ids: 4

PLAN FRAGMENT 3
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 6
    HASH_PARTITIONED: int_col

  1:SCAN HDFS
     table=functional.alltypestiny #partitions=4 size=460B
     tuple ids: 2

PLAN FRAGMENT 4
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 5
    HASH_PARTITIONED: int_col

  0:SCAN HDFS
     table=functional.alltypestiny #partitions=4 size=460B
     tuple ids: 0
====
---- QUERY
# Self-join of with-clause table to make sure the join op is properly set
# in the cloned inline-view instances.
with t as (select int_col x, bigint_col y from functional.alltypestiny)
select * from t t1 left outer join t t2 using(x) full outer join t t3 using(x)
---- PLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  4:HASH JOIN
  |  join op: FULL OUTER JOIN
  |  hash predicates:
  |    int_col = int_col
  |  tuple ids: 0N 2N 4N
  |
  |----3:SCAN HDFS
  |       table=functional.alltypestiny #partitions=4 size=460B compact
  |       tuple ids: 4
  |
  2:HASH JOIN
  |  join op: LEFT OUTER JOIN
  |  hash predicates:
  |    int_col = int_col
  |  tuple ids: 0 2N
  |
  |----1:SCAN HDFS
  |       table=functional.alltypestiny #partitions=4 size=460B compact
  |       tuple ids: 2
  |
  0:SCAN HDFS
     table=functional.alltypestiny #partitions=4 size=460B
     tuple ids: 0
---- DISTRIBUTEDPLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  9:EXCHANGE
     tuple ids: 0N 2N 4N

PLAN FRAGMENT 1
  PARTITION: HASH_PARTITIONED: int_col

  STREAM DATA SINK
    EXCHANGE ID: 9
    UNPARTITIONED

  4:HASH JOIN
  |  join op: FULL OUTER JOIN (PARTITIONED)
  |  hash predicates:
  |    int_col = int_col
  |  tuple ids: 0N 2N 4N
  |
  |----8:EXCHANGE
  |       tuple ids: 4
  |
  7:EXCHANGE
     tuple ids: 0 2N

PLAN FRAGMENT 2
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 8
    HASH_PARTITIONED: int_col

  3:SCAN HDFS
     table=functional.alltypestiny #partitions=4 size=460B
     tuple ids: 4

PLAN FRAGMENT 3
  PARTITION: HASH_PARTITIONED: int_col

  STREAM DATA SINK
    EXCHANGE ID: 7
    HASH_PARTITIONED: int_col

  2:HASH JOIN
  |  join op: LEFT OUTER JOIN (PARTITIONED)
  |  hash predicates:
  |    int_col = int_col
  |  tuple ids: 0 2N
  |
  |----6:EXCHANGE
  |       tuple ids: 2
  |
  5:EXCHANGE
     tuple ids: 0

PLAN FRAGMENT 4
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 6
    HASH_PARTITIONED: int_col

  1:SCAN HDFS
     table=functional.alltypestiny #partitions=4 size=460B
     tuple ids: 2

PLAN FRAGMENT 5
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 5
    HASH_PARTITIONED: int_col

  0:SCAN HDFS
     table=functional.alltypestiny #partitions=4 size=460B
     tuple ids: 0
====
---- QUERY
# Self-join of with-clause table to make sure join hints are properly set
# in the cloned inline-view instances.
# Note that in the plan above without hints the first join uses shuffle
# and the second broadcast.
with t as (select int_col x, bigint_col y from functional.alltypestiny)
select * from t t1 inner join [broadcast] t t2 using(x) inner join [shuffle] t t3 using(x)
---- PLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  4:HASH JOIN
  |  join op: INNER JOIN
  |  hash predicates:
  |    int_col = int_col
  |  tuple ids: 0 2 4
  |
  |----3:SCAN HDFS
  |       table=functional.alltypestiny #partitions=4 size=460B compact
  |       tuple ids: 4
  |
  2:HASH JOIN
  |  join op: INNER JOIN
  |  hash predicates:
  |    int_col = int_col
  |  tuple ids: 0 2
  |
  |----1:SCAN HDFS
  |       table=functional.alltypestiny #partitions=4 size=460B compact
  |       tuple ids: 2
  |
  0:SCAN HDFS
     table=functional.alltypestiny #partitions=4 size=460B
     tuple ids: 0
---- DISTRIBUTEDPLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  8:EXCHANGE
     tuple ids: 0 2 4

PLAN FRAGMENT 1
  PARTITION: HASH_PARTITIONED: int_col

  STREAM DATA SINK
    EXCHANGE ID: 8
    UNPARTITIONED

  4:HASH JOIN
  |  join op: INNER JOIN (PARTITIONED)
  |  hash predicates:
  |    int_col = int_col
  |  tuple ids: 0 2 4
  |
  |----7:EXCHANGE
  |       tuple ids: 4
  |
  6:EXCHANGE
     tuple ids: 0 2

PLAN FRAGMENT 2
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 7
    HASH_PARTITIONED: int_col

  3:SCAN HDFS
     table=functional.alltypestiny #partitions=4 size=460B
     tuple ids: 4

PLAN FRAGMENT 3
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 6
    HASH_PARTITIONED: int_col

  2:HASH JOIN
  |  join op: INNER JOIN (BROADCAST)
  |  hash predicates:
  |    int_col = int_col
  |  tuple ids: 0 2
  |
  |----5:EXCHANGE
  |       tuple ids: 2
  |
  0:SCAN HDFS
     table=functional.alltypestiny #partitions=4 size=460B
     tuple ids: 0

PLAN FRAGMENT 4
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 5
    UNPARTITIONED

  1:SCAN HDFS
     table=functional.alltypestiny #partitions=4 size=460B
     tuple ids: 2
====
---- QUERY
# Multiple with clauses. One for the UnionStmt and one for each union operand.
with t1 as (values('a', 'b'))
(with t2 as (values('c', 'd')) select * from t2) union all
(with t3 as (values('e', 'f')) select * from t3) order by 1 limit 1
---- PLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  3:TOP-N
  |  order by: 'c' ASC
  |  limit: 1
  |  tuple ids: 4
  |
  0:MERGE
  |  tuple ids: 4
  |
  |----2:MERGE
  |       merging 1 SELECT CONSTANT
  |       tuple ids: 2
  |
  1:MERGE
     merging 1 SELECT CONSTANT
     tuple ids: 0
---- DISTRIBUTEDPLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  3:TOP-N
  |  order by: 'c' ASC
  |  limit: 1
  |  tuple ids: 4
  |
  4:EXCHANGE
     tuple ids: 4

PLAN FRAGMENT 1
  PARTITION: UNPARTITIONED

  STREAM DATA SINK
    EXCHANGE ID: 4
    UNPARTITIONED

  6:MERGE
  |  tuple ids: 4
  |
  2:MERGE
     merging 1 SELECT CONSTANT
     tuple ids: 2

PLAN FRAGMENT 2
  PARTITION: UNPARTITIONED

  STREAM DATA SINK
    EXCHANGE ID: 4
    UNPARTITIONED

  5:MERGE
  |  tuple ids: 4
  |
  1:MERGE
     merging 1 SELECT CONSTANT
     tuple ids: 0
====
---- QUERY
# Multiple with clauses. One for the UnionStmt and one for each union operand.
with t1 as (values('a', 'b'))
(with t2 as (values('c', 'd')) select * from t2) union all
(with t3 as (values('e', 'f')) select * from t3) order by 1 limit 1
---- PLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  3:TOP-N
  |  order by: 'c' ASC
  |  limit: 1
  |  tuple ids: 4
  |
  0:MERGE
  |  tuple ids: 4
  |
  |----2:MERGE
  |       merging 1 SELECT CONSTANT
  |       tuple ids: 2
  |
  1:MERGE
     merging 1 SELECT CONSTANT
     tuple ids: 0
---- DISTRIBUTEDPLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  3:TOP-N
  |  order by: 'c' ASC
  |  limit: 1
  |  tuple ids: 4
  |
  4:EXCHANGE
     tuple ids: 4

PLAN FRAGMENT 1
  PARTITION: UNPARTITIONED

  STREAM DATA SINK
    EXCHANGE ID: 4
    UNPARTITIONED

  6:MERGE
  |  tuple ids: 4
  |
  2:MERGE
     merging 1 SELECT CONSTANT
     tuple ids: 2

PLAN FRAGMENT 2
  PARTITION: UNPARTITIONED

  STREAM DATA SINK
    EXCHANGE ID: 4
    UNPARTITIONED

  5:MERGE
  |  tuple ids: 4
  |
  1:MERGE
     merging 1 SELECT CONSTANT
     tuple ids: 0
====
---- QUERY
# Test with clause in an insert statement.
with t1 as (select * from functional.alltypestiny)
insert into functional.alltypesinsert partition(year, month) select * from t1
---- PLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  WRITE TO HDFS table=functional.alltypesinsert
    overwrite=false
    partitions: functional.alltypestiny.year,functional.alltypestiny.month

  0:SCAN HDFS
     table=functional.alltypestiny #partitions=4 size=460B
     tuple ids: 0
---- DISTRIBUTEDPLAN
PLAN FRAGMENT 0
  PARTITION: HASH_PARTITIONED: functional.alltypestiny.year, functional.alltypestiny.month

  WRITE TO HDFS table=functional.alltypesinsert
    overwrite=false
    partitions: functional.alltypestiny.year,functional.alltypestiny.month

  1:EXCHANGE
     tuple ids: 0

PLAN FRAGMENT 1
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 1
    HASH_PARTITIONED: functional.alltypestiny.year, functional.alltypestiny.month

  0:SCAN HDFS
     table=functional.alltypestiny #partitions=4 size=460B
     tuple ids: 0
====
---- QUERY
# Test with clause in an insert statement and in its query statement.
with t1 as (select * from functional.alltypestiny)
insert into functional.alltypesinsert partition(year, month)
with t2 as (select * from functional.alltypestiny)
select * from t1 union all select * from t2
---- PLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  WRITE TO HDFS table=functional.alltypesinsert
    overwrite=false
    partitions: year,month

  0:MERGE
  |  tuple ids: 4
  |
  |----2:SCAN HDFS
  |       table=functional.alltypestiny #partitions=4 size=460B
  |       tuple ids: 2
  |
  1:SCAN HDFS
     table=functional.alltypestiny #partitions=4 size=460B
     tuple ids: 0
---- DISTRIBUTEDPLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  WRITE TO HDFS table=functional.alltypesinsert
    overwrite=false
    partitions: year,month

  3:EXCHANGE
     tuple ids: 4

PLAN FRAGMENT 1
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 3
    UNPARTITIONED

  5:MERGE
  |  tuple ids: 4
  |
  2:SCAN HDFS
     table=functional.alltypestiny #partitions=4 size=460B
     tuple ids: 2

PLAN FRAGMENT 2
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 3
    UNPARTITIONED

  4:MERGE
  |  tuple ids: 4
  |
  1:SCAN HDFS
     table=functional.alltypestiny #partitions=4 size=460B
     tuple ids: 0
====
