# subquery with aggregation and order by/limit, as left-hand side of join;
# having clause in subquery is transfered to merge agg step in distrib plan
select *
from (
  select int_col, count(*)
  from functional.alltypessmall
  where month = 1
  group by int_col
  having count(*) > 1
  order by count(*) desc limit 5
  ) t1
join functional.alltypes t2 on (t1.int_col = t2.int_col)
where month = 1
---- PLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  4:HASH JOIN
  |  join op: INNER JOIN
  |  hash predicates:
  |    int_col = t2.int_col
  |  tuple ids: 1 3
  |
  |----3:SCAN HDFS
  |       table=functional.alltypes #partitions=2 size=40.32KB compact
  |       tuple ids: 3
  |
  2:TOP-N
  |  order by: COUNT(*) DESC
  |  limit: 5
  |  tuple ids: 1
  |
  1:AGGREGATE
  |  output: COUNT(*)
  |  group by: int_col
  |  having: COUNT(*) > 1
  |  tuple ids: 1
  |
  0:SCAN HDFS
     table=functional.alltypessmall #partitions=1 size=1.57KB
     tuple ids: 0
---- DISTRIBUTEDPLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  4:HASH JOIN
  |  join op: INNER JOIN (BROADCAST)
  |  hash predicates:
  |    int_col = t2.int_col
  |  tuple ids: 1 3
  |
  |----9:EXCHANGE
  |       tuple ids: 3
  |
  8:TOP-N
  |  order by: COUNT(*) DESC
  |  limit: 5
  |  tuple ids: 1
  |
  7:EXCHANGE
     tuple ids: 1

PLAN FRAGMENT 1
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 9
    UNPARTITIONED

  3:SCAN HDFS
     table=functional.alltypes #partitions=2 size=40.32KB
     tuple ids: 3

PLAN FRAGMENT 2
  PARTITION: HASH_PARTITIONED: int_col

  STREAM DATA SINK
    EXCHANGE ID: 7
    UNPARTITIONED

  2:TOP-N
  |  order by: COUNT(*) DESC
  |  limit: 5
  |  tuple ids: 1
  |
  6:AGGREGATE
  |  output: SUM(COUNT(*))
  |  group by: int_col
  |  having: COUNT(*) > 1
  |  tuple ids: 1
  |
  5:EXCHANGE
     tuple ids: 1

PLAN FRAGMENT 3
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 5
    HASH_PARTITIONED: int_col

  1:AGGREGATE
  |  output: COUNT(*)
  |  group by: int_col
  |  tuple ids: 1
  |
  0:SCAN HDFS
     table=functional.alltypessmall #partitions=1 size=1.57KB
     tuple ids: 0
---- SCANRANGELOCATIONS
NODE 0:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypessmall/year=2009/month=1/090101.txt 0:1610
NODE 3:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypes/year=2009/month=1/090101.txt 0:20433
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypes/year=2010/month=1/100101.txt 0:20853
====
# simple full scan subquery
select * from (select y x from (select id y from functional_hbase.alltypessmall) a) b
---- PLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  0:SCAN HBASE
     table:alltypessmall
     tuple ids: 0
---- DISTRIBUTEDPLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  1:EXCHANGE
     tuple ids: 0

PLAN FRAGMENT 1
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 1
    UNPARTITIONED

  0:SCAN HBASE
     table:alltypessmall
     tuple ids: 0
---- SCANRANGELOCATIONS
NODE 0:
  HBASE KEYRANGE port=60201 <unbounded>:3
  HBASE KEYRANGE port=60202 3:7
  HBASE KEYRANGE port=60203 7:<unbounded>
====
# subquery doing join
select * from (select t2.*
from functional.testtbl t1 join functional.testtbl t2 using(id)
where t1.zip = 94611) x
---- PLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  2:HASH JOIN
  |  join op: INNER JOIN
  |  hash predicates:
  |    t1.id = t2.id
  |  tuple ids: 0 1
  |
  |----1:SCAN HDFS
  |       table=functional.testtbl #partitions=0 size=0B compact
  |       tuple ids: 1
  |
  0:SCAN HDFS
     table=functional.testtbl #partitions=0 size=0B
     predicates: t1.zip = 94611
     tuple ids: 0
---- DISTRIBUTEDPLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  4:EXCHANGE
     tuple ids: 0 1

PLAN FRAGMENT 1
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 4
    UNPARTITIONED

  2:HASH JOIN
  |  join op: INNER JOIN (BROADCAST)
  |  hash predicates:
  |    t1.id = t2.id
  |  tuple ids: 0 1
  |
  |----3:EXCHANGE
  |       tuple ids: 1
  |
  0:SCAN HDFS
     table=functional.testtbl #partitions=0 size=0B
     predicates: t1.zip = 94611
     tuple ids: 0

PLAN FRAGMENT 2
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 3
    UNPARTITIONED

  1:SCAN HDFS
     table=functional.testtbl #partitions=0 size=0B
     tuple ids: 1
---- SCANRANGELOCATIONS
NODE 0:
NODE 1:
====
# subquery doing join
# multiple join predicates;
# scan predicates get propagated correctly;
# non-eq join predicates are evaluated as extra conjuncts by the join node
select * from (select a.*
from functional.alltypesagg a right outer join functional.alltypessmall b using (id, int_col)
where a.day >= 6
and b.month > 2
and a.tinyint_col = 15
and b.string_col = '15'
and a.tinyint_col + b.tinyint_col < 15) x
---- PLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  2:HASH JOIN
  |  join op: RIGHT OUTER JOIN
  |  hash predicates:
  |    a.id = b.id
  |    a.int_col = b.int_col
  |  other predicates: a.day >= 6, a.tinyint_col = 15, a.tinyint_col + b.tinyint_col < 15
  |  tuple ids: 0N 1
  |
  |----1:SCAN HDFS
  |       table=functional.alltypessmall #partitions=2 size=3.17KB compact
  |       predicates: b.string_col = '15'
  |       tuple ids: 1
  |
  0:SCAN HDFS
     table=functional.alltypesagg #partitions=10 size=743.67KB
     tuple ids: 0
---- DISTRIBUTEDPLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  5:EXCHANGE
     tuple ids: 0N 1

PLAN FRAGMENT 1
  PARTITION: HASH_PARTITIONED: a.id, a.int_col

  STREAM DATA SINK
    EXCHANGE ID: 5
    UNPARTITIONED

  2:HASH JOIN
  |  join op: RIGHT OUTER JOIN (PARTITIONED)
  |  hash predicates:
  |    a.id = b.id
  |    a.int_col = b.int_col
  |  other predicates: a.day >= 6, a.tinyint_col = 15, a.tinyint_col + b.tinyint_col < 15
  |  tuple ids: 0N 1
  |
  |----4:EXCHANGE
  |       tuple ids: 1
  |
  3:EXCHANGE
     tuple ids: 0

PLAN FRAGMENT 2
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 4
    HASH_PARTITIONED: b.id, b.int_col

  1:SCAN HDFS
     table=functional.alltypessmall #partitions=2 size=3.17KB
     predicates: b.string_col = '15'
     tuple ids: 1

PLAN FRAGMENT 3
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 3
    HASH_PARTITIONED: a.id, a.int_col

  0:SCAN HDFS
     table=functional.alltypesagg #partitions=10 size=743.67KB
     tuple ids: 0
---- SCANRANGELOCATIONS
NODE 0:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=1/100101.txt 0:75153
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=10/100110.txt 0:76263
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=2/100102.txt 0:76263
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=3/100103.txt 0:76263
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=4/100104.txt 0:76263
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=5/100105.txt 0:76263
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=6/100106.txt 0:76263
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=7/100107.txt 0:76263
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=8/100108.txt 0:76263
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=9/100109.txt 0:76263
NODE 1:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypessmall/year=2009/month=3/090301.txt 0:1620
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypessmall/year=2009/month=4/090401.txt 0:1621
====
# predicate pushdown
select * from (select * from functional_hbase.alltypessmall) a where id < 5
---- PLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  0:SCAN HBASE
     table:alltypessmall
     predicates: functional_hbase.alltypessmall.id < 5
     tuple ids: 0
---- DISTRIBUTEDPLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  1:EXCHANGE
     tuple ids: 0

PLAN FRAGMENT 1
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 1
    UNPARTITIONED

  0:SCAN HBASE
     table:alltypessmall
     predicates: functional_hbase.alltypessmall.id < 5
     tuple ids: 0
---- SCANRANGELOCATIONS
NODE 0:
  HBASE KEYRANGE port=60201 <unbounded>:3
  HBASE KEYRANGE port=60202 3:7
  HBASE KEYRANGE port=60203 7:<unbounded>
====
# subquery join
# multiple join predicates;
# scan predicates get propagated correctly;
# non-eq join predicates are evaluated as extra conjuncts by the join node
select *
from (select id, int_col, day, tinyint_col from functional.alltypesagg) a right outer join
     (select id, int_col, month, string_col, tinyint_col from functional.alltypessmall) b using (id, int_col)
where a.day >= 6
and b.month > 2
and a.tinyint_col = 15
and b.string_col = '15'
and a.tinyint_col + b.tinyint_col < 15
---- PLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  2:HASH JOIN
  |  join op: RIGHT OUTER JOIN
  |  hash predicates:
  |    id = id
  |    int_col = int_col
  |  other predicates: day >= 6, tinyint_col = 15, tinyint_col + tinyint_col < 15
  |  tuple ids: 0N 2
  |
  |----1:SCAN HDFS
  |       table=functional.alltypessmall #partitions=2 size=3.17KB compact
  |       predicates: string_col = '15'
  |       tuple ids: 2
  |
  0:SCAN HDFS
     table=functional.alltypesagg #partitions=10 size=743.67KB
     tuple ids: 0
---- DISTRIBUTEDPLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  5:EXCHANGE
     tuple ids: 0N 2

PLAN FRAGMENT 1
  PARTITION: HASH_PARTITIONED: id, int_col

  STREAM DATA SINK
    EXCHANGE ID: 5
    UNPARTITIONED

  2:HASH JOIN
  |  join op: RIGHT OUTER JOIN (PARTITIONED)
  |  hash predicates:
  |    id = id
  |    int_col = int_col
  |  other predicates: day >= 6, tinyint_col = 15, tinyint_col + tinyint_col < 15
  |  tuple ids: 0N 2
  |
  |----4:EXCHANGE
  |       tuple ids: 2
  |
  3:EXCHANGE
     tuple ids: 0

PLAN FRAGMENT 2
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 4
    HASH_PARTITIONED: id, int_col

  1:SCAN HDFS
     table=functional.alltypessmall #partitions=2 size=3.17KB
     predicates: string_col = '15'
     tuple ids: 2

PLAN FRAGMENT 3
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 3
    HASH_PARTITIONED: id, int_col

  0:SCAN HDFS
     table=functional.alltypesagg #partitions=10 size=743.67KB
     tuple ids: 0
---- SCANRANGELOCATIONS
NODE 0:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=1/100101.txt 0:75153
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=10/100110.txt 0:76263
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=2/100102.txt 0:76263
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=3/100103.txt 0:76263
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=4/100104.txt 0:76263
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=5/100105.txt 0:76263
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=6/100106.txt 0:76263
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=7/100107.txt 0:76263
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=8/100108.txt 0:76263
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=9/100109.txt 0:76263
NODE 1:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypessmall/year=2009/month=3/090301.txt 0:1620
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypessmall/year=2009/month=4/090401.txt 0:1621
====
# subquery join
# multiple join predicates;
# scan predicates get propagated correctly;
# non-eq join predicates are evaluated as extra conjuncts by the join node
select *
from (select id, int_col, day, tinyint_col
      from (select id, int_col, day, tinyint_col from functional.alltypesagg) a0
      where a0.day >= 6) a
     right outer join
     (select id, int_col, month, string_col, tinyint_col from functional.alltypessmall) b using (id, int_col)
where b.month > 2
and a.tinyint_col = 15
and b.string_col = '15'
and a.tinyint_col + b.tinyint_col < 15
---- PLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  2:HASH JOIN
  |  join op: RIGHT OUTER JOIN
  |  hash predicates:
  |    id = id
  |    int_col = int_col
  |  other predicates: tinyint_col = 15, tinyint_col + tinyint_col < 15
  |  tuple ids: 0N 3
  |
  |----1:SCAN HDFS
  |       table=functional.alltypessmall #partitions=2 size=3.17KB compact
  |       predicates: string_col = '15'
  |       tuple ids: 3
  |
  0:SCAN HDFS
     table=functional.alltypesagg #partitions=5 size=372.38KB
     tuple ids: 0
---- DISTRIBUTEDPLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  5:EXCHANGE
     tuple ids: 0N 3

PLAN FRAGMENT 1
  PARTITION: HASH_PARTITIONED: id, int_col

  STREAM DATA SINK
    EXCHANGE ID: 5
    UNPARTITIONED

  2:HASH JOIN
  |  join op: RIGHT OUTER JOIN (PARTITIONED)
  |  hash predicates:
  |    id = id
  |    int_col = int_col
  |  other predicates: tinyint_col = 15, tinyint_col + tinyint_col < 15
  |  tuple ids: 0N 3
  |
  |----4:EXCHANGE
  |       tuple ids: 3
  |
  3:EXCHANGE
     tuple ids: 0

PLAN FRAGMENT 2
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 4
    HASH_PARTITIONED: id, int_col

  1:SCAN HDFS
     table=functional.alltypessmall #partitions=2 size=3.17KB
     predicates: string_col = '15'
     tuple ids: 3

PLAN FRAGMENT 3
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 3
    HASH_PARTITIONED: id, int_col

  0:SCAN HDFS
     table=functional.alltypesagg #partitions=5 size=372.38KB
     tuple ids: 0
---- SCANRANGELOCATIONS
NODE 0:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=10/100110.txt 0:76263
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=6/100106.txt 0:76263
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=7/100107.txt 0:76263
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=8/100108.txt 0:76263
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=9/100109.txt 0:76263
NODE 1:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypessmall/year=2009/month=3/090301.txt 0:1620
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypessmall/year=2009/month=4/090401.txt 0:1621
====
# complex join, having joined subquery on the rhs, and predicate
# at multiple subquery level. This tests that both sides of a join
# that is itself on the build side of another join get compacted.
select x.smallint_col, x.id, x.tinyint_col, c.id, x.int_col, x.float_col, c.string_col
from functional.alltypessmall c
join (
   select a.smallint_col smallint_col, a.tinyint_col tinyint_col, a.day day,
           a.int_col int_col, a.month month, b.float_col float_col, b.id id
   from ( select * from functional.alltypesagg a where month=1 ) a
   join functional.alltypessmall b on (a.smallint_col = b.id)
 ) x on (x.tinyint_col = c.id)
where x.day=1
and x.int_col > 899
and x.float_col > 4.5
and c.string_col < '7'
and x.int_col + x.float_col + cast(c.string_col as float) < 1000
---- PLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  4:HASH JOIN
  |  join op: INNER JOIN
  |  hash predicates:
  |    c.id = a.tinyint_col
  |  other predicates: a.int_col + b.float_col + CAST(c.string_col AS FLOAT) < 1000.0
  |  tuple ids: 0 1 3
  |
  |----3:HASH JOIN
  |    |  join op: INNER JOIN
  |    |  hash predicates:
  |    |    a.smallint_col = b.id
  |    |  tuple ids: 1 3
  |    |
  |    |----2:SCAN HDFS
  |    |       table=functional.alltypessmall #partitions=4 size=6.32KB compact
  |    |       predicates: b.float_col > 4.5
  |    |       tuple ids: 3
  |    |
  |    1:SCAN HDFS
  |       table=functional.alltypesagg #partitions=1 size=73.39KB compact
  |       predicates: a.int_col > 899
  |       tuple ids: 1
  |
  0:SCAN HDFS
     table=functional.alltypessmall #partitions=4 size=6.32KB
     predicates: c.string_col < '7'
     tuple ids: 0
---- DISTRIBUTEDPLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  8:EXCHANGE
     tuple ids: 0 1 3

PLAN FRAGMENT 1
  PARTITION: HASH_PARTITIONED: c.id

  STREAM DATA SINK
    EXCHANGE ID: 8
    UNPARTITIONED

  4:HASH JOIN
  |  join op: INNER JOIN (PARTITIONED)
  |  hash predicates:
  |    c.id = a.tinyint_col
  |  other predicates: a.int_col + b.float_col + CAST(c.string_col AS FLOAT) < 1000.0
  |  tuple ids: 0 1 3
  |
  |----7:EXCHANGE
  |       tuple ids: 1 3
  |
  6:EXCHANGE
     tuple ids: 0

PLAN FRAGMENT 2
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 7
    HASH_PARTITIONED: a.tinyint_col

  3:HASH JOIN
  |  join op: INNER JOIN (BROADCAST)
  |  hash predicates:
  |    a.smallint_col = b.id
  |  tuple ids: 1 3
  |
  |----5:EXCHANGE
  |       tuple ids: 3
  |
  1:SCAN HDFS
     table=functional.alltypesagg #partitions=1 size=73.39KB
     predicates: a.int_col > 899
     tuple ids: 1

PLAN FRAGMENT 3
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 5
    UNPARTITIONED

  2:SCAN HDFS
     table=functional.alltypessmall #partitions=4 size=6.32KB
     predicates: b.float_col > 4.5
     tuple ids: 3

PLAN FRAGMENT 4
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 6
    HASH_PARTITIONED: c.id

  0:SCAN HDFS
     table=functional.alltypessmall #partitions=4 size=6.32KB
     predicates: c.string_col < '7'
     tuple ids: 0
---- SCANRANGELOCATIONS
NODE 0:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypessmall/year=2009/month=1/090101.txt 0:1610
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypessmall/year=2009/month=2/090201.txt 0:1621
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypessmall/year=2009/month=3/090301.txt 0:1620
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypessmall/year=2009/month=4/090401.txt 0:1621
NODE 1:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=1/100101.txt 0:75153
NODE 2:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypessmall/year=2009/month=1/090101.txt 0:1610
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypessmall/year=2009/month=2/090201.txt 0:1621
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypessmall/year=2009/month=3/090301.txt 0:1620
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypessmall/year=2009/month=4/090401.txt 0:1621
====
# with grouping
select tinyint_col, count(*), min(tinyint_col), max(tinyint_col), sum(tinyint_col),
avg(tinyint_col)
from (select * from functional.alltypesagg) a
group by 1
---- PLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  1:AGGREGATE
  |  output: COUNT(*), MIN(functional.alltypesagg.tinyint_col), MAX(functional.alltypesagg.tinyint_col), SUM(functional.alltypesagg.tinyint_col), COUNT(functional.alltypesagg.tinyint_col)
  |  group by: functional.alltypesagg.tinyint_col
  |  tuple ids: 2
  |
  0:SCAN HDFS
     table=functional.alltypesagg #partitions=10 size=743.67KB
     tuple ids: 0
---- DISTRIBUTEDPLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  4:EXCHANGE
     tuple ids: 2

PLAN FRAGMENT 1
  PARTITION: HASH_PARTITIONED: tinyint_col

  STREAM DATA SINK
    EXCHANGE ID: 4
    UNPARTITIONED

  3:AGGREGATE
  |  output: SUM(COUNT(*)), MIN(MIN(tinyint_col)), MAX(MAX(tinyint_col)), SUM(SUM(tinyint_col)), SUM(COUNT(tinyint_col))
  |  group by: tinyint_col
  |  tuple ids: 2
  |
  2:EXCHANGE
     tuple ids: 2

PLAN FRAGMENT 2
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 2
    HASH_PARTITIONED: tinyint_col

  1:AGGREGATE
  |  output: COUNT(*), MIN(functional.alltypesagg.tinyint_col), MAX(functional.alltypesagg.tinyint_col), SUM(functional.alltypesagg.tinyint_col), COUNT(functional.alltypesagg.tinyint_col)
  |  group by: functional.alltypesagg.tinyint_col
  |  tuple ids: 2
  |
  0:SCAN HDFS
     table=functional.alltypesagg #partitions=10 size=743.67KB
     tuple ids: 0
---- SCANRANGELOCATIONS
NODE 0:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=1/100101.txt 0:75153
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=10/100110.txt 0:76263
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=2/100102.txt 0:76263
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=3/100103.txt 0:76263
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=4/100104.txt 0:76263
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=5/100105.txt 0:76263
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=6/100106.txt 0:76263
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=7/100107.txt 0:76263
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=8/100108.txt 0:76263
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=9/100109.txt 0:76263
====
# with grouping
select * from (
select tinyint_col, count(*), min(tinyint_col), max(tinyint_col), sum(tinyint_col),
avg(tinyint_col)
from functional.alltypesagg
group by 1
) a
---- PLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  1:AGGREGATE
  |  output: COUNT(*), MIN(tinyint_col), MAX(tinyint_col), SUM(tinyint_col), COUNT(tinyint_col)
  |  group by: tinyint_col
  |  tuple ids: 1
  |
  0:SCAN HDFS
     table=functional.alltypesagg #partitions=10 size=743.67KB
     tuple ids: 0
---- DISTRIBUTEDPLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  4:EXCHANGE
     tuple ids: 1

PLAN FRAGMENT 1
  PARTITION: HASH_PARTITIONED: tinyint_col

  STREAM DATA SINK
    EXCHANGE ID: 4
    UNPARTITIONED

  3:AGGREGATE
  |  output: SUM(COUNT(*)), MIN(MIN(tinyint_col)), MAX(MAX(tinyint_col)), SUM(SUM(tinyint_col)), SUM(COUNT(tinyint_col))
  |  group by: tinyint_col
  |  tuple ids: 1
  |
  2:EXCHANGE
     tuple ids: 1

PLAN FRAGMENT 2
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 2
    HASH_PARTITIONED: tinyint_col

  1:AGGREGATE
  |  output: COUNT(*), MIN(tinyint_col), MAX(tinyint_col), SUM(tinyint_col), COUNT(tinyint_col)
  |  group by: tinyint_col
  |  tuple ids: 1
  |
  0:SCAN HDFS
     table=functional.alltypesagg #partitions=10 size=743.67KB
     tuple ids: 0
---- SCANRANGELOCATIONS
NODE 0:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=1/100101.txt 0:75153
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=10/100110.txt 0:76263
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=2/100102.txt 0:76263
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=3/100103.txt 0:76263
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=4/100104.txt 0:76263
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=5/100105.txt 0:76263
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=6/100106.txt 0:76263
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=7/100107.txt 0:76263
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=8/100108.txt 0:76263
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=9/100109.txt 0:76263
====
select c1, c2, c3
from (
  select c1, c2, c3
  from (
    select int_col c1, sum(float_col) c2, min(float_col) c3
    from functional_hbase.alltypessmall
    group by 1
  ) x
  order by 2,3 desc
  limit 5
) y
---- PLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  2:TOP-N
  |  order by: SUM(float_col) ASC, MIN(float_col) DESC
  |  limit: 5
  |  tuple ids: 1
  |
  1:AGGREGATE
  |  output: SUM(float_col), MIN(float_col)
  |  group by: int_col
  |  tuple ids: 1
  |
  0:SCAN HBASE
     table:alltypessmall
     tuple ids: 0
---- DISTRIBUTEDPLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  6:TOP-N
  |  order by: SUM(float_col) ASC, MIN(float_col) DESC
  |  limit: 5
  |  tuple ids: 1
  |
  5:EXCHANGE
     tuple ids: 1

PLAN FRAGMENT 1
  PARTITION: HASH_PARTITIONED: int_col

  STREAM DATA SINK
    EXCHANGE ID: 5
    UNPARTITIONED

  2:TOP-N
  |  order by: SUM(float_col) ASC, MIN(float_col) DESC
  |  limit: 5
  |  tuple ids: 1
  |
  4:AGGREGATE
  |  output: SUM(SUM(float_col)), MIN(MIN(float_col))
  |  group by: int_col
  |  tuple ids: 1
  |
  3:EXCHANGE
     tuple ids: 1

PLAN FRAGMENT 2
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 3
    HASH_PARTITIONED: int_col

  1:AGGREGATE
  |  output: SUM(float_col), MIN(float_col)
  |  group by: int_col
  |  tuple ids: 1
  |
  0:SCAN HBASE
     table:alltypessmall
     tuple ids: 0
---- SCANRANGELOCATIONS
NODE 0:
  HBASE KEYRANGE port=60201 <unbounded>:3
  HBASE KEYRANGE port=60202 3:7
  HBASE KEYRANGE port=60203 7:<unbounded>
====
select c1, x2
from (
  select c1, min(c2) x2
  from (
    select c1, c2, c3
    from (
      select int_col c1, tinyint_col c2, min(float_col) c3
      from functional_hbase.alltypessmall
      group by 1, 2
      order by 1,2
      limit 1
    ) x
  ) x2
  group by c1
) y
order by 2,1 desc
limit 0
---- PLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  4:TOP-N
  |  order by: MIN(c2) ASC, c1 DESC
  |  limit: 0
  |  tuple ids: 4
  |
  3:AGGREGATE
  |  output: MIN(tinyint_col)
  |  group by: int_col
  |  tuple ids: 4
  |
  2:TOP-N
  |  order by: int_col ASC, tinyint_col ASC
  |  limit: 1
  |  tuple ids: 1
  |
  1:AGGREGATE
  |  output: MIN(float_col)
  |  group by: int_col, tinyint_col
  |  tuple ids: 1
  |
  0:SCAN HBASE
     table:alltypessmall
     tuple ids: 0
---- DISTRIBUTEDPLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  4:TOP-N
  |  order by: MIN(c2) ASC, c1 DESC
  |  limit: 0
  |  tuple ids: 4
  |
  3:AGGREGATE
  |  output: MIN(tinyint_col)
  |  group by: int_col
  |  tuple ids: 4
  |
  8:TOP-N
  |  order by: int_col ASC, tinyint_col ASC
  |  limit: 1
  |  tuple ids: 1
  |
  7:EXCHANGE
     tuple ids: 1

PLAN FRAGMENT 1
  PARTITION: HASH_PARTITIONED: int_col, tinyint_col

  STREAM DATA SINK
    EXCHANGE ID: 7
    UNPARTITIONED

  2:TOP-N
  |  order by: int_col ASC, tinyint_col ASC
  |  limit: 1
  |  tuple ids: 1
  |
  6:AGGREGATE
  |  output: MIN(MIN(float_col))
  |  group by: int_col, tinyint_col
  |  tuple ids: 1
  |
  5:EXCHANGE
     tuple ids: 1

PLAN FRAGMENT 2
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 5
    HASH_PARTITIONED: int_col, tinyint_col

  1:AGGREGATE
  |  output: MIN(float_col)
  |  group by: int_col, tinyint_col
  |  tuple ids: 1
  |
  0:SCAN HBASE
     table:alltypessmall
     tuple ids: 0
---- SCANRANGELOCATIONS
NODE 0:
  HBASE KEYRANGE port=60201 <unbounded>:3
  HBASE KEYRANGE port=60202 3:7
  HBASE KEYRANGE port=60203 7:<unbounded>
====
# distinct *
select distinct *
from (select distinct * from functional.testtbl) x
---- PLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  2:AGGREGATE
  |  group by: functional.testtbl.id, functional.testtbl.name, functional.testtbl.zip
  |  tuple ids: 3
  |
  1:AGGREGATE
  |  group by: functional.testtbl.id, functional.testtbl.name, functional.testtbl.zip
  |  tuple ids: 1
  |
  0:SCAN HDFS
     table=functional.testtbl #partitions=0 size=0B
     tuple ids: 0
---- DISTRIBUTEDPLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  7:EXCHANGE
     tuple ids: 3

PLAN FRAGMENT 1
  PARTITION: HASH_PARTITIONED: x.id, x.name, x.zip

  STREAM DATA SINK
    EXCHANGE ID: 7
    UNPARTITIONED

  6:AGGREGATE
  |  group by: x.id, x.name, x.zip
  |  tuple ids: 3
  |
  5:EXCHANGE
     tuple ids: 3

PLAN FRAGMENT 2
  PARTITION: HASH_PARTITIONED: functional.testtbl.id, functional.testtbl.name, functional.testtbl.zip

  STREAM DATA SINK
    EXCHANGE ID: 5
    HASH_PARTITIONED: x.id, x.name, x.zip

  2:AGGREGATE
  |  group by: functional.testtbl.id, functional.testtbl.name, functional.testtbl.zip
  |  tuple ids: 3
  |
  4:AGGREGATE
  |  group by: functional.testtbl.id, functional.testtbl.name, functional.testtbl.zip
  |  tuple ids: 1
  |
  3:EXCHANGE
     tuple ids: 1

PLAN FRAGMENT 3
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 3
    HASH_PARTITIONED: functional.testtbl.id, functional.testtbl.name, functional.testtbl.zip

  1:AGGREGATE
  |  group by: functional.testtbl.id, functional.testtbl.name, functional.testtbl.zip
  |  tuple ids: 1
  |
  0:SCAN HDFS
     table=functional.testtbl #partitions=0 size=0B
     tuple ids: 0
---- SCANRANGELOCATIONS
NODE 0:
====
# distinct w/ explicit select list
select distinct id, zip
from (select distinct * from functional.testtbl) x
---- PLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  2:AGGREGATE
  |  group by: functional.testtbl.id, functional.testtbl.zip
  |  tuple ids: 3
  |
  1:AGGREGATE
  |  group by: functional.testtbl.id, functional.testtbl.name, functional.testtbl.zip
  |  tuple ids: 1
  |
  0:SCAN HDFS
     table=functional.testtbl #partitions=0 size=0B
     tuple ids: 0
---- DISTRIBUTEDPLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  7:EXCHANGE
     tuple ids: 3

PLAN FRAGMENT 1
  PARTITION: HASH_PARTITIONED: id, zip

  STREAM DATA SINK
    EXCHANGE ID: 7
    UNPARTITIONED

  6:AGGREGATE
  |  group by: id, zip
  |  tuple ids: 3
  |
  5:EXCHANGE
     tuple ids: 3

PLAN FRAGMENT 2
  PARTITION: HASH_PARTITIONED: functional.testtbl.id, functional.testtbl.name, functional.testtbl.zip

  STREAM DATA SINK
    EXCHANGE ID: 5
    HASH_PARTITIONED: id, zip

  2:AGGREGATE
  |  group by: functional.testtbl.id, functional.testtbl.zip
  |  tuple ids: 3
  |
  4:AGGREGATE
  |  group by: functional.testtbl.id, functional.testtbl.name, functional.testtbl.zip
  |  tuple ids: 1
  |
  3:EXCHANGE
     tuple ids: 1

PLAN FRAGMENT 3
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 3
    HASH_PARTITIONED: functional.testtbl.id, functional.testtbl.name, functional.testtbl.zip

  1:AGGREGATE
  |  group by: functional.testtbl.id, functional.testtbl.name, functional.testtbl.zip
  |  tuple ids: 1
  |
  0:SCAN HDFS
     table=functional.testtbl #partitions=0 size=0B
     tuple ids: 0
---- SCANRANGELOCATIONS
NODE 0:
====
# aggregate with group-by, having
select *
from (
       select int_col % 7 c1, count(*) c2, avg(int_col) c3
       from (
              select * from functional.alltypesagg
            ) a
       group by 1
       having avg(int_col) > 500 or count(*) = 10
     ) b
where c1 is not null
and   c2 > 10
---- PLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  1:AGGREGATE
  |  output: COUNT(*), SUM(functional.alltypesagg.int_col), COUNT(functional.alltypesagg.int_col)
  |  group by: functional.alltypesagg.int_col % 7
  |  having: SUM(int_col) / COUNT(int_col) > 500.0 OR COUNT(*) = 10, int_col % 7 IS NOT NULL, COUNT(*) > 10
  |  tuple ids: 2
  |
  0:SCAN HDFS
     table=functional.alltypesagg #partitions=10 size=743.67KB
     tuple ids: 0
---- DISTRIBUTEDPLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  4:EXCHANGE
     tuple ids: 2

PLAN FRAGMENT 1
  PARTITION: HASH_PARTITIONED: int_col % 7

  STREAM DATA SINK
    EXCHANGE ID: 4
    UNPARTITIONED

  3:AGGREGATE
  |  output: SUM(COUNT(*)), SUM(SUM(int_col)), SUM(COUNT(int_col))
  |  group by: int_col % 7
  |  having: SUM(int_col) / COUNT(int_col) > 500.0 OR COUNT(*) = 10, int_col % 7 IS NOT NULL, COUNT(*) > 10
  |  tuple ids: 2
  |
  2:EXCHANGE
     tuple ids: 2

PLAN FRAGMENT 2
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 2
    HASH_PARTITIONED: int_col % 7

  1:AGGREGATE
  |  output: COUNT(*), SUM(functional.alltypesagg.int_col), COUNT(functional.alltypesagg.int_col)
  |  group by: functional.alltypesagg.int_col % 7
  |  tuple ids: 2
  |
  0:SCAN HDFS
     table=functional.alltypesagg #partitions=10 size=743.67KB
     tuple ids: 0
---- SCANRANGELOCATIONS
NODE 0:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=1/100101.txt 0:75153
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=10/100110.txt 0:76263
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=2/100102.txt 0:76263
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=3/100103.txt 0:76263
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=4/100104.txt 0:76263
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=5/100105.txt 0:76263
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=6/100106.txt 0:76263
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=7/100107.txt 0:76263
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=8/100108.txt 0:76263
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=9/100109.txt 0:76263
====
# subquery with left outer join
select j.*, d.*
from (
       select *
       from functional.JoinTbl a
     ) j
     left outer join
     (
       select *
       from functional.DimTbl b
     ) d
     on (j.test_name = d.name)
where j.test_id <= 1006
---- PLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  2:HASH JOIN
  |  join op: LEFT OUTER JOIN
  |  hash predicates:
  |    a.test_name = b.name
  |  tuple ids: 0 2N
  |
  |----1:SCAN HDFS
  |       table=functional.dimtbl #partitions=1 size=171B compact
  |       tuple ids: 2
  |
  0:SCAN HDFS
     table=functional.jointbl #partitions=1 size=433B
     predicates: a.test_id <= 1006
     tuple ids: 0
---- DISTRIBUTEDPLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  5:EXCHANGE
     tuple ids: 0 2N

PLAN FRAGMENT 1
  PARTITION: HASH_PARTITIONED: a.test_name

  STREAM DATA SINK
    EXCHANGE ID: 5
    UNPARTITIONED

  2:HASH JOIN
  |  join op: LEFT OUTER JOIN (PARTITIONED)
  |  hash predicates:
  |    a.test_name = b.name
  |  tuple ids: 0 2N
  |
  |----4:EXCHANGE
  |       tuple ids: 2
  |
  3:EXCHANGE
     tuple ids: 0

PLAN FRAGMENT 2
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 4
    HASH_PARTITIONED: b.name

  1:SCAN HDFS
     table=functional.dimtbl #partitions=1 size=171B
     tuple ids: 2

PLAN FRAGMENT 3
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 3
    HASH_PARTITIONED: a.test_name

  0:SCAN HDFS
     table=functional.jointbl #partitions=1 size=433B
     predicates: a.test_id <= 1006
     tuple ids: 0
---- SCANRANGELOCATIONS
NODE 0:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/jointbl/data.csv 0:433
NODE 1:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/dimtbl/data.csv 0:171
====
# complex join, having joined subquery on the rhs, and predicate
# at multiple subquery level
select x.smallint_col, count(x.id)
from functional.alltypessmall c
     left outer join
     (
       select a.smallint_col smallint_col, a.tinyint_col tinyint_col, a.day day,
               a.int_col int_col, a.month month, b.float_col float_col, b.id id
        from (
                select *
                from functional.alltypesagg a
             ) a
             join
             functional.alltypessmall b
             on (a.smallint_col = b.id)
     ) x
     on (x.tinyint_col = c.id)
group by x.smallint_col
---- PLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  5:AGGREGATE
  |  output: COUNT(b.id)
  |  group by: a.smallint_col
  |  tuple ids: 5
  |
  4:HASH JOIN
  |  join op: LEFT OUTER JOIN
  |  hash predicates:
  |    c.id = a.tinyint_col
  |  tuple ids: 0 1N 3N
  |
  |----3:HASH JOIN
  |    |  join op: INNER JOIN
  |    |  hash predicates:
  |    |    a.smallint_col = b.id
  |    |  tuple ids: 1 3
  |    |
  |    |----2:SCAN HDFS
  |    |       table=functional.alltypessmall #partitions=4 size=6.32KB compact
  |    |       tuple ids: 3
  |    |
  |    1:SCAN HDFS
  |       table=functional.alltypesagg #partitions=10 size=743.67KB compact
  |       tuple ids: 1
  |
  0:SCAN HDFS
     table=functional.alltypessmall #partitions=4 size=6.32KB
     tuple ids: 0
---- DISTRIBUTEDPLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  11:EXCHANGE
     tuple ids: 5

PLAN FRAGMENT 1
  PARTITION: HASH_PARTITIONED: x.smallint_col

  STREAM DATA SINK
    EXCHANGE ID: 11
    UNPARTITIONED

  10:AGGREGATE
  |  output: SUM(COUNT(x.id))
  |  group by: x.smallint_col
  |  tuple ids: 5
  |
  9:EXCHANGE
     tuple ids: 5

PLAN FRAGMENT 2
  PARTITION: HASH_PARTITIONED: c.id

  STREAM DATA SINK
    EXCHANGE ID: 9
    HASH_PARTITIONED: x.smallint_col

  5:AGGREGATE
  |  output: COUNT(b.id)
  |  group by: a.smallint_col
  |  tuple ids: 5
  |
  4:HASH JOIN
  |  join op: LEFT OUTER JOIN (PARTITIONED)
  |  hash predicates:
  |    c.id = a.tinyint_col
  |  tuple ids: 0 1N 3N
  |
  |----8:EXCHANGE
  |       tuple ids: 1 3
  |
  7:EXCHANGE
     tuple ids: 0

PLAN FRAGMENT 3
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 8
    HASH_PARTITIONED: a.tinyint_col

  3:HASH JOIN
  |  join op: INNER JOIN (BROADCAST)
  |  hash predicates:
  |    a.smallint_col = b.id
  |  tuple ids: 1 3
  |
  |----6:EXCHANGE
  |       tuple ids: 3
  |
  1:SCAN HDFS
     table=functional.alltypesagg #partitions=10 size=743.67KB
     tuple ids: 1

PLAN FRAGMENT 4
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 6
    UNPARTITIONED

  2:SCAN HDFS
     table=functional.alltypessmall #partitions=4 size=6.32KB
     tuple ids: 3

PLAN FRAGMENT 5
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 7
    HASH_PARTITIONED: c.id

  0:SCAN HDFS
     table=functional.alltypessmall #partitions=4 size=6.32KB
     tuple ids: 0
---- SCANRANGELOCATIONS
NODE 0:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypessmall/year=2009/month=1/090101.txt 0:1610
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypessmall/year=2009/month=2/090201.txt 0:1621
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypessmall/year=2009/month=3/090301.txt 0:1620
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypessmall/year=2009/month=4/090401.txt 0:1621
NODE 1:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=1/100101.txt 0:75153
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=10/100110.txt 0:76263
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=2/100102.txt 0:76263
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=3/100103.txt 0:76263
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=4/100104.txt 0:76263
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=5/100105.txt 0:76263
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=6/100106.txt 0:76263
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=7/100107.txt 0:76263
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=8/100108.txt 0:76263
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=9/100109.txt 0:76263
NODE 2:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypessmall/year=2009/month=1/090101.txt 0:1610
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypessmall/year=2009/month=2/090201.txt 0:1621
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypessmall/year=2009/month=3/090301.txt 0:1620
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypessmall/year=2009/month=4/090401.txt 0:1621
====
# complex join, having joined subquery on the lhs, and predicate
# at multiple subquery level
select x.smallint_col, x.id, x.tinyint_col, c.id, x.int_col, x.float_col, c.string_col
from
     (
       select a.smallint_col smallint_col, a.tinyint_col tinyint_col, a.day day,
               a.int_col int_col, a.month month, b.float_col float_col, b.id id
        from (
                select *
                from functional.alltypesagg a
                where month=1
             ) a
             join
             functional.alltypessmall b
             on (a.smallint_col = b.id)
     ) x
     join
      functional.alltypessmall c
     on (x.tinyint_col = c.id)
where x.day=1
and x.int_col > 899
and x.float_col > 4.5
and c.string_col < '7'
and x.int_col + x.float_col + CAST(c.string_col AS FLOAT) < 1000
---- PLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  4:HASH JOIN
  |  join op: INNER JOIN
  |  hash predicates:
  |    a.tinyint_col = c.id
  |  other predicates: a.int_col + b.float_col + CAST(c.string_col AS FLOAT) < 1000.0
  |  tuple ids: 0 2 4
  |
  |----3:SCAN HDFS
  |       table=functional.alltypessmall #partitions=4 size=6.32KB compact
  |       predicates: c.string_col < '7'
  |       tuple ids: 4
  |
  2:HASH JOIN
  |  join op: INNER JOIN
  |  hash predicates:
  |    a.smallint_col = b.id
  |  tuple ids: 0 2
  |
  |----1:SCAN HDFS
  |       table=functional.alltypessmall #partitions=4 size=6.32KB compact
  |       predicates: b.float_col > 4.5
  |       tuple ids: 2
  |
  0:SCAN HDFS
     table=functional.alltypesagg #partitions=1 size=73.39KB
     predicates: a.int_col > 899
     tuple ids: 0
---- DISTRIBUTEDPLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  7:EXCHANGE
     tuple ids: 0 2 4

PLAN FRAGMENT 1
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 7
    UNPARTITIONED

  4:HASH JOIN
  |  join op: INNER JOIN (BROADCAST)
  |  hash predicates:
  |    a.tinyint_col = c.id
  |  other predicates: a.int_col + b.float_col + CAST(c.string_col AS FLOAT) < 1000.0
  |  tuple ids: 0 2 4
  |
  |----6:EXCHANGE
  |       tuple ids: 4
  |
  2:HASH JOIN
  |  join op: INNER JOIN (BROADCAST)
  |  hash predicates:
  |    a.smallint_col = b.id
  |  tuple ids: 0 2
  |
  |----5:EXCHANGE
  |       tuple ids: 2
  |
  0:SCAN HDFS
     table=functional.alltypesagg #partitions=1 size=73.39KB
     predicates: a.int_col > 899
     tuple ids: 0

PLAN FRAGMENT 2
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 6
    UNPARTITIONED

  3:SCAN HDFS
     table=functional.alltypessmall #partitions=4 size=6.32KB
     predicates: c.string_col < '7'
     tuple ids: 4

PLAN FRAGMENT 3
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 5
    UNPARTITIONED

  1:SCAN HDFS
     table=functional.alltypessmall #partitions=4 size=6.32KB
     predicates: b.float_col > 4.5
     tuple ids: 2
---- SCANRANGELOCATIONS
NODE 0:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=1/100101.txt 0:75153
NODE 1:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypessmall/year=2009/month=1/090101.txt 0:1610
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypessmall/year=2009/month=2/090201.txt 0:1621
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypessmall/year=2009/month=3/090301.txt 0:1620
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypessmall/year=2009/month=4/090401.txt 0:1621
NODE 3:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypessmall/year=2009/month=1/090101.txt 0:1610
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypessmall/year=2009/month=2/090201.txt 0:1621
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypessmall/year=2009/month=3/090301.txt 0:1620
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypessmall/year=2009/month=4/090401.txt 0:1621
====
# complex join, having joined aggregate subquery on the rhs, and predicate
# at multiple subquery level
select x.smallint_col, sum(x.cnt)
from functional.alltypessmall c
  join (
    select count(a.id) cnt, b.smallint_col smallint_col
    from ( select * from functional.alltypesagg a ) a
      join functional.alltypessmall b on (a.smallint_col = b.id)
    group by b.smallint_col
  ) x on (x.smallint_col = c.id)
group by x.smallint_col
---- PLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  6:AGGREGATE
  |  output: SUM(COUNT(a.id))
  |  group by: b.smallint_col
  |  tuple ids: 6
  |
  5:HASH JOIN
  |  join op: INNER JOIN
  |  hash predicates:
  |    c.id = b.smallint_col
  |  tuple ids: 0 4
  |
  |----4:AGGREGATE
  |    |  output: COUNT(a.id)
  |    |  group by: b.smallint_col
  |    |  tuple ids: 4
  |    |
  |    3:HASH JOIN
  |    |  join op: INNER JOIN
  |    |  hash predicates:
  |    |    a.smallint_col = b.id
  |    |  tuple ids: 1 3
  |    |
  |    |----2:SCAN HDFS
  |    |       table=functional.alltypessmall #partitions=4 size=6.32KB compact
  |    |       tuple ids: 3
  |    |
  |    1:SCAN HDFS
  |       table=functional.alltypesagg #partitions=10 size=743.67KB
  |       tuple ids: 1
  |
  0:SCAN HDFS
     table=functional.alltypessmall #partitions=4 size=6.32KB
     tuple ids: 0
---- DISTRIBUTEDPLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  13:EXCHANGE
     tuple ids: 6

PLAN FRAGMENT 1
  PARTITION: HASH_PARTITIONED: x.smallint_col

  STREAM DATA SINK
    EXCHANGE ID: 13
    UNPARTITIONED

  12:AGGREGATE
  |  output: SUM(SUM(x.cnt))
  |  group by: x.smallint_col
  |  tuple ids: 6
  |
  11:EXCHANGE
     tuple ids: 6

PLAN FRAGMENT 2
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 11
    HASH_PARTITIONED: x.smallint_col

  6:AGGREGATE
  |  output: SUM(COUNT(a.id))
  |  group by: b.smallint_col
  |  tuple ids: 6
  |
  5:HASH JOIN
  |  join op: INNER JOIN (BROADCAST)
  |  hash predicates:
  |    c.id = b.smallint_col
  |  tuple ids: 0 4
  |
  |----10:EXCHANGE
  |       tuple ids: 4
  |
  0:SCAN HDFS
     table=functional.alltypessmall #partitions=4 size=6.32KB
     tuple ids: 0

PLAN FRAGMENT 3
  PARTITION: HASH_PARTITIONED: b.smallint_col

  STREAM DATA SINK
    EXCHANGE ID: 10
    UNPARTITIONED

  9:AGGREGATE
  |  output: SUM(COUNT(a.id))
  |  group by: b.smallint_col
  |  tuple ids: 4
  |
  8:EXCHANGE
     tuple ids: 4

PLAN FRAGMENT 4
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 8
    HASH_PARTITIONED: b.smallint_col

  4:AGGREGATE
  |  output: COUNT(a.id)
  |  group by: b.smallint_col
  |  tuple ids: 4
  |
  3:HASH JOIN
  |  join op: INNER JOIN (BROADCAST)
  |  hash predicates:
  |    a.smallint_col = b.id
  |  tuple ids: 1 3
  |
  |----7:EXCHANGE
  |       tuple ids: 3
  |
  1:SCAN HDFS
     table=functional.alltypesagg #partitions=10 size=743.67KB
     tuple ids: 1

PLAN FRAGMENT 5
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 7
    UNPARTITIONED

  2:SCAN HDFS
     table=functional.alltypessmall #partitions=4 size=6.32KB
     tuple ids: 3
---- SCANRANGELOCATIONS
NODE 0:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypessmall/year=2009/month=1/090101.txt 0:1610
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypessmall/year=2009/month=2/090201.txt 0:1621
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypessmall/year=2009/month=3/090301.txt 0:1620
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypessmall/year=2009/month=4/090401.txt 0:1621
NODE 1:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=1/100101.txt 0:75153
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=10/100110.txt 0:76263
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=2/100102.txt 0:76263
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=3/100103.txt 0:76263
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=4/100104.txt 0:76263
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=5/100105.txt 0:76263
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=6/100106.txt 0:76263
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=7/100107.txt 0:76263
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=8/100108.txt 0:76263
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypesagg/year=2010/month=1/day=9/100109.txt 0:76263
NODE 2:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypessmall/year=2009/month=1/090101.txt 0:1610
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypessmall/year=2009/month=2/090201.txt 0:1621
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypessmall/year=2009/month=3/090301.txt 0:1620
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypessmall/year=2009/month=4/090401.txt 0:1621
====
# Constant selects in subqueries
select * from (select 1, 2) x
---- PLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  0:MERGE
     merging 1 SELECT CONSTANT
     tuple ids: 0
---- DISTRIBUTEDPLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  0:MERGE
     merging 1 SELECT CONSTANT
     tuple ids: 0
====
# Constant selects in subqueries with predicate
select * from (select y from (select 1 y) a where y < 10) b
---- PLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  0:MERGE
     predicates: 1 < 10
     merging 1 SELECT CONSTANT
     tuple ids: 0
---- DISTRIBUTEDPLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  0:MERGE
     predicates: 1 < 10
     merging 1 SELECT CONSTANT
     tuple ids: 0
====
# Union of constant selects in subquery
# TODO: We could combine the merge nodes below.
select * from (select 1 union all select 2 union all select * from (select 3) y) x
---- PLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  0:MERGE
  |  merging 2 SELECT CONSTANT
  |  tuple ids: 1
  |
  1:MERGE
     merging 1 SELECT CONSTANT
     tuple ids: 0
---- DISTRIBUTEDPLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  2:EXCHANGE
     tuple ids: 1

PLAN FRAGMENT 1
  PARTITION: UNPARTITIONED

  STREAM DATA SINK
    EXCHANGE ID: 2
    UNPARTITIONED

  4:MERGE
     merging 2 SELECT CONSTANT
     tuple ids: 1

PLAN FRAGMENT 2
  PARTITION: UNPARTITIONED

  STREAM DATA SINK
    EXCHANGE ID: 2
    UNPARTITIONED

  3:MERGE
  |  tuple ids: 1
  |
  1:MERGE
     merging 1 SELECT CONSTANT
     tuple ids: 0
====
# Values statement in subqueries
select * from (values(1, 2)) x
---- PLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  0:MERGE
     merging 1 SELECT CONSTANT
     tuple ids: 0
---- DISTRIBUTEDPLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  0:MERGE
     merging 1 SELECT CONSTANT
     tuple ids: 0
====
# Values statement in subqueries with predicate
select * from (select y from (values(1 as y)) a where y < 10) b
---- PLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  0:MERGE
     predicates: <slot 0> < 10
     merging 1 SELECT CONSTANT
     tuple ids: 0
---- DISTRIBUTEDPLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  0:MERGE
     predicates: <slot 0> < 10
     merging 1 SELECT CONSTANT
     tuple ids: 0
====
# Union of values statements in subquery
# TODO: We could combine the merge nodes below.
select * from (values(1) union all values(2) union all select * from (values(3)) y) x
---- PLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  0:MERGE
  |  merging 2 SELECT CONSTANT
  |  tuple ids: 4
  |
  1:MERGE
     merging 1 SELECT CONSTANT
     tuple ids: 2
---- DISTRIBUTEDPLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  2:EXCHANGE
     tuple ids: 4

PLAN FRAGMENT 1
  PARTITION: UNPARTITIONED

  STREAM DATA SINK
    EXCHANGE ID: 2
    UNPARTITIONED

  4:MERGE
     merging 2 SELECT CONSTANT
     tuple ids: 4

PLAN FRAGMENT 2
  PARTITION: UNPARTITIONED

  STREAM DATA SINK
    EXCHANGE ID: 2
    UNPARTITIONED

  3:MERGE
  |  tuple ids: 4
  |
  1:MERGE
     merging 1 SELECT CONSTANT
     tuple ids: 2
====
# Inner join on inline views made up of unions of constant selects
select * from
(select 1 a, 2 b union all select 1 a, 2 b) x
inner join
(select 1 a, 3 b union all select 1 a, 2 b) y on x.a = y.a
inner join
(select 1 a, 3 b union all select 1 a, 3 b) z on z.b = y.b
---- PLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  4:HASH JOIN
  |  join op: INNER JOIN
  |  hash predicates:
  |    <slot 5> = <slot 9>
  |  tuple ids: 0 2 4
  |
  |----3:MERGE
  |       merging 2 SELECT CONSTANT
  |       tuple ids: 4
  |
  2:HASH JOIN
  |  join op: INNER JOIN
  |  hash predicates:
  |    <slot 0> = <slot 4>
  |  tuple ids: 0 2
  |
  |----1:MERGE
  |       merging 2 SELECT CONSTANT
  |       tuple ids: 2
  |
  0:MERGE
     merging 2 SELECT CONSTANT
     tuple ids: 0
---- DISTRIBUTEDPLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  4:HASH JOIN
  |  join op: INNER JOIN (BROADCAST)
  |  hash predicates:
  |    <slot 5> = <slot 9>
  |  tuple ids: 0 2 4
  |
  |----6:EXCHANGE
  |       tuple ids: 4
  |
  2:HASH JOIN
  |  join op: INNER JOIN (BROADCAST)
  |  hash predicates:
  |    <slot 0> = <slot 4>
  |  tuple ids: 0 2
  |
  |----5:EXCHANGE
  |       tuple ids: 2
  |
  0:MERGE
     merging 2 SELECT CONSTANT
     tuple ids: 0

PLAN FRAGMENT 1
  PARTITION: UNPARTITIONED

  STREAM DATA SINK
    EXCHANGE ID: 6
    UNPARTITIONED

  3:MERGE
     merging 2 SELECT CONSTANT
     tuple ids: 4

PLAN FRAGMENT 2
  PARTITION: UNPARTITIONED

  STREAM DATA SINK
    EXCHANGE ID: 5
    UNPARTITIONED

  1:MERGE
     merging 2 SELECT CONSTANT
     tuple ids: 2
====
# Semi and inner join on a table and on inline views made up of constant selects
select * from functional.alltypessmall x
left semi join
(select 1 a, 3 b union all select 1 a, 3 b) y on y.a = x.id
inner join
(select 1 a, 3 b union all select 1 a, 3 b) z on z.b = y.b
---- PLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  4:HASH JOIN
  |  join op: INNER JOIN
  |  hash predicates:
  |    <slot 1> = <slot 6>
  |  tuple ids: 0 1 3
  |
  |----3:MERGE
  |       merging 2 SELECT CONSTANT
  |       tuple ids: 3
  |
  2:HASH JOIN
  |  join op: LEFT SEMI JOIN
  |  hash predicates:
  |    x.id = <slot 0>
  |  tuple ids: 0 1
  |
  |----1:MERGE
  |       merging 2 SELECT CONSTANT
  |       tuple ids: 1
  |
  0:SCAN HDFS
     table=functional.alltypessmall #partitions=4 size=6.32KB
     tuple ids: 0
---- DISTRIBUTEDPLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  7:EXCHANGE
     tuple ids: 0 1 3

PLAN FRAGMENT 1
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 7
    UNPARTITIONED

  4:HASH JOIN
  |  join op: INNER JOIN (BROADCAST)
  |  hash predicates:
  |    <slot 1> = <slot 6>
  |  tuple ids: 0 1 3
  |
  |----6:EXCHANGE
  |       tuple ids: 3
  |
  2:HASH JOIN
  |  join op: LEFT SEMI JOIN (BROADCAST)
  |  hash predicates:
  |    x.id = <slot 0>
  |  tuple ids: 0 1
  |
  |----5:EXCHANGE
  |       tuple ids: 1
  |
  0:SCAN HDFS
     table=functional.alltypessmall #partitions=4 size=6.32KB
     tuple ids: 0

PLAN FRAGMENT 2
  PARTITION: UNPARTITIONED

  STREAM DATA SINK
    EXCHANGE ID: 6
    UNPARTITIONED

  3:MERGE
     merging 2 SELECT CONSTANT
     tuple ids: 3

PLAN FRAGMENT 3
  PARTITION: UNPARTITIONED

  STREAM DATA SINK
    EXCHANGE ID: 5
    UNPARTITIONED

  1:MERGE
     merging 2 SELECT CONSTANT
     tuple ids: 1
====
