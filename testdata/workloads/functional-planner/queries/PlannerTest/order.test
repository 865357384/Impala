select name, zip
from functional.testtbl
order by name
---- PLAN
not implemented: ORDER BY without LIMIT currently not supported
====
select zip, count(*)
from functional.testtbl
where name like 'm%'
group by 1
order by 2 desc
---- PLAN
not implemented: ORDER BY without LIMIT currently not supported
====
select int_col, sum(float_col)
from functional_hbase.alltypessmall
where id < 5
group by 1
order by 2
---- PLAN
not implemented: ORDER BY without LIMIT currently not supported
====
select int_col, sum(float_col), min(float_col)
from functional_hbase.alltypessmall
group by 1
order by 2,3 desc
---- PLAN
not implemented: ORDER BY without LIMIT currently not supported
====
# Test correct identification of the implicit aliasing of int_col in the select
# list to t1.int_col;
# t2.int_col is not null references enough cols of t2 to prevent a broadcast join
select t1.int_col
from functional.alltypessmall t1, functional.alltypessmall t2
where t1.id = t2.id and t2.int_col is not null
order by int_col
limit 2
---- PLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  3:TOP-N
  |  order by: t1.int_col ASC
  |  limit: 2
  |
  2:HASH JOIN
  |  join op: INNER JOIN
  |  hash predicates:
  |    t1.id = t2.id
  |
  |----1:SCAN HDFS
  |       table=functional.alltypessmall #partitions=4/4 size=6.32KB compact
  |       predicates: t2.int_col IS NOT NULL
  |
  0:SCAN HDFS
     table=functional.alltypessmall #partitions=4/4 size=6.32KB
---- DISTRIBUTEDPLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  7:TOP-N
  |  order by: t1.int_col ASC
  |  limit: 2
  |
  6:EXCHANGE

PLAN FRAGMENT 1
  PARTITION: HASH_PARTITIONED: t1.id

  STREAM DATA SINK
    EXCHANGE ID: 6
    UNPARTITIONED

  3:TOP-N
  |  order by: t1.int_col ASC
  |  limit: 2
  |
  2:HASH JOIN
  |  join op: INNER JOIN (PARTITIONED)
  |  hash predicates:
  |    t1.id = t2.id
  |
  |----5:EXCHANGE
  |
  4:EXCHANGE

PLAN FRAGMENT 2
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 5
    HASH_PARTITIONED: t2.id

  1:SCAN HDFS
     table=functional.alltypessmall #partitions=4/4 size=6.32KB
     predicates: t2.int_col IS NOT NULL

PLAN FRAGMENT 3
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 4
    HASH_PARTITIONED: t1.id

  0:SCAN HDFS
     table=functional.alltypessmall #partitions=4/4 size=6.32KB
---- SCANRANGELOCATIONS
NODE 0:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypessmall/year=2009/month=1/090101.txt 0:1610
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypessmall/year=2009/month=2/090201.txt 0:1621
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypessmall/year=2009/month=3/090301.txt 0:1620
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypessmall/year=2009/month=4/090401.txt 0:1621
NODE 1:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypessmall/year=2009/month=1/090101.txt 0:1610
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypessmall/year=2009/month=2/090201.txt 0:1621
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypessmall/year=2009/month=3/090301.txt 0:1620
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypessmall/year=2009/month=4/090401.txt 0:1621
====
# Test that the sort is on int_col and not on the id column
select int_col as id from functional.alltypessmall order by id limit 2
---- PLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  1:TOP-N
  |  order by: int_col ASC
  |  limit: 2
  |
  0:SCAN HDFS
     table=functional.alltypessmall #partitions=4/4 size=6.32KB
---- DISTRIBUTEDPLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  3:TOP-N
  |  order by: int_col ASC
  |  limit: 2
  |
  2:EXCHANGE

PLAN FRAGMENT 1
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 2
    UNPARTITIONED

  1:TOP-N
  |  order by: int_col ASC
  |  limit: 2
  |
  0:SCAN HDFS
     table=functional.alltypessmall #partitions=4/4 size=6.32KB
---- SCANRANGELOCATIONS
NODE 0:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypessmall/year=2009/month=1/090101.txt 0:1610
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypessmall/year=2009/month=2/090201.txt 0:1621
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypessmall/year=2009/month=3/090301.txt 0:1620
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypessmall/year=2009/month=4/090401.txt 0:1621
====
# Test that the sort is on id and not on int_col
select int_col as id from functional.alltypessmall order by functional.alltypessmall.id limit 2
---- PLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  1:TOP-N
  |  order by: functional.alltypessmall.id ASC
  |  limit: 2
  |
  0:SCAN HDFS
     table=functional.alltypessmall #partitions=4/4 size=6.32KB
---- DISTRIBUTEDPLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  3:TOP-N
  |  order by: functional.alltypessmall.id ASC
  |  limit: 2
  |
  2:EXCHANGE

PLAN FRAGMENT 1
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 2
    UNPARTITIONED

  1:TOP-N
  |  order by: functional.alltypessmall.id ASC
  |  limit: 2
  |
  0:SCAN HDFS
     table=functional.alltypessmall #partitions=4/4 size=6.32KB
---- SCANRANGELOCATIONS
NODE 0:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypessmall/year=2009/month=1/090101.txt 0:1610
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypessmall/year=2009/month=2/090201.txt 0:1621
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypessmall/year=2009/month=3/090301.txt 0:1620
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypessmall/year=2009/month=4/090401.txt 0:1621
====
# Test that the limit/offset is propagated correctly to child nodes. The TOP-N node
# should have the limit/offset specified in the query. Child sort nodes should have a
# limit equal to the parent's (limit + offset) and offset equal to 0.
select t1.int_col from functional.alltypessmall t1, functional.alltypessmall t2
where t1.id = t2.id and t2.int_col is not null
order by int_col
limit 10 offset 5
---- PLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  3:TOP-N
  |  order by: t1.int_col ASC
  |  limit: 10
  |  offset: 5
  |
  2:HASH JOIN
  |  join op: INNER JOIN
  |  hash predicates:
  |    t1.id = t2.id
  |
  |----1:SCAN HDFS
  |       table=functional.alltypessmall #partitions=4/4 size=6.32KB compact
  |       predicates: t2.int_col IS NOT NULL
  |
  0:SCAN HDFS
     table=functional.alltypessmall #partitions=4/4 size=6.32KB
---- DISTRIBUTEDPLAN
PLAN FRAGMENT 0
  PARTITION: UNPARTITIONED

  7:TOP-N
  |  order by: t1.int_col ASC
  |  limit: 10
  |  offset: 5
  |
  6:EXCHANGE

PLAN FRAGMENT 1
  PARTITION: HASH_PARTITIONED: t1.id

  STREAM DATA SINK
    EXCHANGE ID: 6
    UNPARTITIONED

  3:TOP-N
  |  order by: t1.int_col ASC
  |  limit: 15
  |
  2:HASH JOIN
  |  join op: INNER JOIN (PARTITIONED)
  |  hash predicates:
  |    t1.id = t2.id
  |
  |----5:EXCHANGE
  |
  4:EXCHANGE

PLAN FRAGMENT 2
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 5
    HASH_PARTITIONED: t2.id

  1:SCAN HDFS
     table=functional.alltypessmall #partitions=4/4 size=6.32KB
     predicates: t2.int_col IS NOT NULL

PLAN FRAGMENT 3
  PARTITION: RANDOM

  STREAM DATA SINK
    EXCHANGE ID: 4
    HASH_PARTITIONED: t1.id

  0:SCAN HDFS
     table=functional.alltypessmall #partitions=4/4 size=6.32KB
---- SCANRANGELOCATIONS
NODE 0:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypessmall/year=2009/month=1/090101.txt 0:1610
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypessmall/year=2009/month=2/090201.txt 0:1621
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypessmall/year=2009/month=3/090301.txt 0:1620
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypessmall/year=2009/month=4/090401.txt 0:1621
NODE 1:
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypessmall/year=2009/month=1/090101.txt 0:1610
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypessmall/year=2009/month=2/090201.txt 0:1621
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypessmall/year=2009/month=3/090301.txt 0:1620
  HDFS SPLIT hdfs://localhost:20500/test-warehouse/alltypessmall/year=2009/month=4/090401.txt 0:1621
====
